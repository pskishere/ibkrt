
#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
åŸºäºyfinanceçš„è‚¡ç¥¨æ•°æ®åˆ†ææœåŠ¡ - RESTful APIæœåŠ¡
æä¾›æŠ€æœ¯æŒ‡æ ‡åˆ†æã€AIåˆ†æã€Kçº¿æ•°æ®ç¼“å­˜ç­‰åŠŸèƒ½
æ•°æ®æ¥æºï¼šYahoo Finance (yfinance)
"""

# æ ‡å‡†åº“å¯¼å…¥
import logging
import threading
import time
import sqlite3
import json
import os
from datetime import datetime, date, timedelta
import pandas as pd
import numpy as np

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import requests
import yfinance as yf
from flask import Flask, jsonify, request
from flask_cors import CORS

# æŠ€æœ¯æŒ‡æ ‡æ¨¡å—å¯¼å…¥
from indicators import (
    calculate_ma, calculate_rsi, calculate_bollinger, calculate_macd,
    calculate_volume, calculate_price_change, calculate_volatility,
    calculate_support_resistance, calculate_kdj, calculate_atr,
    calculate_williams_r, calculate_obv, analyze_trend_strength,
    calculate_fibonacci_retracement, calculate_chanlun_analysis, get_trend,
    calculate_cci, calculate_adx, calculate_vwap, calculate_sar,
    calculate_supertrend, calculate_stoch_rsi, calculate_volume_profile,
    calculate_ichimoku
)
from indicators.ml_predictions import calculate_ml_predictions

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)
CORS(app)

DB_PATH = 'stock_cache.db'

def init_database():
    """
    åˆå§‹åŒ–SQLiteæ•°æ®åº“ï¼Œåˆ›å»ºåˆ†æç»“æœç¼“å­˜è¡¨ã€è‚¡ç¥¨ä¿¡æ¯è¡¨å’ŒKçº¿æ•°æ®è¡¨
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # åˆ›å»ºåˆ†æç»“æœç¼“å­˜è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS analysis_cache (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT NOT NULL,
            duration TEXT NOT NULL,
            bar_size TEXT NOT NULL,
            query_date DATE NOT NULL,
            indicators TEXT NOT NULL,
            signals TEXT NOT NULL,
            candles TEXT NOT NULL,
            ai_analysis TEXT,
            model TEXT,
            ai_available INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(symbol, duration, bar_size, query_date)
        )
    ''')
    
    # åˆ›å»ºè‚¡ç¥¨ä¿¡æ¯è¡¨ï¼Œç”¨äºç¼“å­˜è‚¡ç¥¨ä»£ç å’Œå…¨å
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS stock_info (
            symbol TEXT PRIMARY KEY,
            name TEXT,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # åˆ›å»¾Kçº¿æ•°æ®è¡¨ï¼Œç”¨äºç¼“å­˜å…¨é‡Kçº¿æ•°æ®
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS kline_data (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT NOT NULL,
            interval TEXT NOT NULL,
            date TEXT NOT NULL,
            open REAL NOT NULL,
            high REAL NOT NULL,
            low REAL NOT NULL,
            close REAL NOT NULL,
            volume INTEGER NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(symbol, interval, date)
        )
    ''')
    
    # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢é€Ÿåº¦
    cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_symbol_duration_bar_date 
        ON analysis_cache(symbol, duration, bar_size, query_date)
    ''')
    
    cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_kline_symbol_interval_date 
        ON kline_data(symbol, interval, date DESC)
    ''')
    
    conn.commit()
    conn.close()
    logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

def get_cached_analysis(symbol, duration, bar_size):
    """
    ä»æ•°æ®åº“è·å–å½“å¤©çš„åˆ†æç»“æœ
    è¿”å›: å¦‚æœæœ‰å½“å¤©çš„æ•°æ®è¿”å›ç»“æœå­—å…¸ï¼Œå¦åˆ™è¿”å›None
    """
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        today = date.today().isoformat()
        
        cursor.execute('''
            SELECT indicators, signals, candles, ai_analysis, model, ai_available
            FROM analysis_cache
            WHERE symbol = ? AND duration = ? AND bar_size = ? AND query_date = ?
        ''', (symbol.upper(), duration, bar_size, today))
        
        row = cursor.fetchone()
        conn.close()
        
        if row:
            logger.info(f"ä»ç¼“å­˜è·å–æ•°æ®: {symbol}, {duration}, {bar_size}")
            return {
                'success': True,
                'indicators': json.loads(row[0]),
                'signals': json.loads(row[1]),
                'candles': json.loads(row[2]),
                'ai_analysis': row[3],
                'model': row[4],
                'ai_available': bool(row[5])
            }
        else:
            return None
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ç¼“å­˜å¤±è´¥: {e}")
        return None

class JSONEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†pandas Timestampç­‰ç‰¹æ®Šç±»å‹"""
    def default(self, obj):
        if isinstance(obj, pd.Timestamp):
            return obj.strftime('%Y-%m-%d')
        elif isinstance(obj, (pd.Series, pd.DataFrame)):
            return obj.to_dict()
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif pd.isna(obj):
            return None
        return super().default(obj)

def save_analysis_cache(symbol, duration, bar_size, result):
    """
    ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“ï¼ˆæ›´æ–°æˆ–æ’å…¥ï¼‰
    """
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        today = date.today().isoformat()
        
        # ä½¿ç”¨è‡ªå®šä¹‰ç¼–ç å™¨åºåˆ—åŒ–æ•°æ®
        indicators_json = json.dumps(result.get('indicators', {}), cls=JSONEncoder, ensure_ascii=False)
        signals_json = json.dumps(result.get('signals', {}), cls=JSONEncoder, ensure_ascii=False)
        candles_json = json.dumps(result.get('candles', []), cls=JSONEncoder, ensure_ascii=False)
        
        # ä½¿ç”¨ INSERT OR REPLACE æ¥æ›´æ–°æˆ–æ’å…¥æ•°æ®
        cursor.execute('''
            INSERT OR REPLACE INTO analysis_cache 
            (symbol, duration, bar_size, query_date, indicators, signals, candles, 
             ai_analysis, model, ai_available)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            symbol.upper(),
            duration,
            bar_size,
            today,
            indicators_json,
            signals_json,
            candles_json,
            result.get('ai_analysis'),
            result.get('model'),
            1 if result.get('ai_available') else 0
        ))
        
        conn.commit()
        conn.close()
        logger.info(f"åˆ†æç»“æœå·²ç¼“å­˜: {symbol}, {duration}, {bar_size}")
    except Exception as e:
        logger.error(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

def cleanup_old_cache():
    """
    æ›´æ–°éå½“å¤©çš„æ—§æ•°æ®ï¼ˆä¿ç•™å†å²æ•°æ®ï¼Œä¸å†åˆ é™¤ï¼‰
    """
    # ä¸å†åˆ é™¤æ—§æ•°æ®ï¼Œä¿ç•™å†å²è®°å½•
    pass

def save_stock_info(symbol, name):
    """
    ä¿å­˜æˆ–æ›´æ–°è‚¡ç¥¨ä¿¡æ¯ï¼ˆä»£ç å’Œå…¨åï¼‰
    """
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # ä½¿ç”¨ INSERT OR REPLACE æ¥æ›´æ–°æˆ–æ’å…¥
        cursor.execute('''
            INSERT OR REPLACE INTO stock_info (symbol, name, updated_at)
            VALUES (?, ?, CURRENT_TIMESTAMP)
        ''', (symbol.upper(), name))
        
        conn.commit()
        conn.close()
        logger.info(f"è‚¡ç¥¨ä¿¡æ¯å·²ä¿å­˜: {symbol} - {name}")
    except Exception as e:
        logger.error(f"ä¿å­˜è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")

def get_stock_name(symbol):
    """
    ä»æ•°æ®åº“è·å–è‚¡ç¥¨å…¨å
    è¿”å›: è‚¡ç¥¨å…¨åï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
    """
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT name FROM stock_info WHERE symbol = ?
        ''', (symbol.upper(),))
        
        row = cursor.fetchone()
        conn.close()
        
        if row:
            return row[0]
        else:
            return None
    except Exception as e:
        logger.error(f"æŸ¥è¯¢è‚¡ç¥¨åç§°å¤±è´¥: {e}")
        return None


# ==================== YFinance æ•°æ®å‡½æ•° ====================

def get_stock_info(symbol: str):
        """
        è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯
        """
        try:
            ticker = yf.Ticker(symbol)
            info = ticker.info
            
            if not info:
                return None
            
            return {
                'symbol': symbol,
                'longName': info.get('longName', info.get('shortName', symbol)),
                'shortName': info.get('shortName', ''),
                'exchange': info.get('exchange', ''),
                'currency': info.get('currency', 'USD'),
                'marketCap': info.get('marketCap', 0),
                'regularMarketPrice': info.get('regularMarketPrice', 0),
                'fiftyTwoWeekHigh': info.get('fiftyTwoWeekHigh', 0),
                'fiftyTwoWeekLow': info.get('fiftyTwoWeekLow', 0),
            }
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            return None

def _format_financial_dataframe(df):
    """
    æ ¼å¼åŒ–è´¢åŠ¡æŠ¥è¡¨DataFrameä¸ºåˆ—è¡¨æ ¼å¼ï¼ˆå­—å…¸åˆ—è¡¨ï¼‰
    å°†DataFrameè½¬æ¢ä¸ºåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªæ—¥æœŸå¯¹åº”çš„è®°å½•
    """
    if df is None or df.empty:
        return []
    
    result = []
    # è½¬ç½®DataFrameï¼Œä½¿æ—¥æœŸä¸ºé”®
    df_transposed = df.T
    
    for date in df_transposed.index:
        # å¤„ç†æ—¥æœŸï¼šè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if hasattr(date, 'strftime'):
            date_str = date.strftime('%Y-%m-%d')
        elif isinstance(date, pd.Timestamp):
            date_str = date.strftime('%Y-%m-%d')
        else:
            date_str = str(date)
        
        record = {'index': date_str, 'Date': date_str}
        for col in df_transposed.columns:
            value = df_transposed.loc[date, col]
            # å¤„ç†NaNå€¼
            if pd.notna(value):
                # å¤„ç† Timestamp å¯¹è±¡
                if isinstance(value, pd.Timestamp):
                    record[col] = value.strftime('%Y-%m-%d')
                elif isinstance(value, (int, float, np.number)):
                    record[col] = float(value)
                else:
                    record[col] = str(value)
            else:
                record[col] = None
        
        result.append(record)
    
    return result

def get_fundamental_data(symbol: str):
    """
    è·å–åŸºæœ¬é¢æ•°æ®ï¼ˆä»yfinanceï¼‰
    è¿”å›å…¬å¸è´¢åŠ¡æ•°æ®ã€ä¼°å€¼æŒ‡æ ‡ã€è´¢åŠ¡æŠ¥è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨ç­‰
    """
    try:
        ticker = yf.Ticker(symbol)
        info = ticker.info
        
        if not info:
            return None
        
        # è®¡ç®—æ¯è‚¡ç°é‡‘ï¼ˆé¿å…é™¤é›¶é”™è¯¯ï¼‰
        shares_outstanding = info.get('sharesOutstanding', 0)
        total_cash = info.get('totalCash', 0)
        cash_per_share = (total_cash / shares_outstanding) if shares_outstanding and shares_outstanding > 0 else 0
        
        # æå–åŸºæœ¬é¢å…³é”®æŒ‡æ ‡
        fundamental = {
            # å…¬å¸ä¿¡æ¯
            'CompanyName': info.get('longName', info.get('shortName', symbol)),
            'ShortName': info.get('shortName', ''),
            'Exchange': info.get('exchange', ''),
            'Currency': info.get('currency', 'USD'),
            'Sector': info.get('sector', ''),
            'Industry': info.get('industry', ''),
            'Website': info.get('website', ''),
            'Employees': info.get('fullTimeEmployees', 0),
            'BusinessSummary': info.get('longBusinessSummary', ''),
            
            # å¸‚å€¼ä¸ä»·æ ¼
            'MarketCap': info.get('marketCap', 0),
            'EnterpriseValue': info.get('enterpriseValue', 0),
            'Price': info.get('currentPrice', info.get('regularMarketPrice', 0)),
            'PreviousClose': info.get('previousClose', 0),
            '52WeekHigh': info.get('fiftyTwoWeekHigh', 0),
            '52WeekLow': info.get('fiftyTwoWeekLow', 0),
            'SharesOutstanding': shares_outstanding,
            
            # ä¼°å€¼æŒ‡æ ‡
            'PE': info.get('trailingPE', 0),  # å¸‚ç›ˆç‡
            'ForwardPE': info.get('forwardPE', 0),  # é¢„æœŸå¸‚ç›ˆç‡
            'PriceToBook': info.get('priceToBook', 0),  # å¸‚å‡€ç‡
            'PriceToSales': info.get('priceToSalesTrailing12Months', 0),  # å¸‚é”€ç‡
            'PEGRatio': info.get('pegRatio', 0),  # PEGæ¯”ç‡
            'EVToRevenue': info.get('enterpriseToRevenue', 0),  # ä¼ä¸šä»·å€¼/è¥æ”¶
            'EVToEBITDA': info.get('enterpriseToEbitda', 0),  # ä¼ä¸šä»·å€¼/EBITDA
            
            # ç›ˆåˆ©èƒ½åŠ›
            'ProfitMargin': info.get('profitMargins', 0),  # å‡€åˆ©æ¶¦ç‡
            'OperatingMargin': info.get('operatingMargins', 0),  # è¥ä¸šåˆ©æ¶¦ç‡
            'GrossMargin': info.get('grossMargins', 0),  # æ¯›åˆ©ç‡
            'ROE': info.get('returnOnEquity', 0),  # ROE
            'ROA': info.get('returnOnAssets', 0),  # ROA
            'ROIC': info.get('returnOnInvestedCapital', 0),  # æŠ•èµ„å›æŠ¥ç‡
            
            # è´¢åŠ¡å¥åº·
            'RevenueTTM': info.get('totalRevenue', 0),  # æ€»æ”¶å…¥(TTM)
            'RevenuePerShare': info.get('revenuePerShare', 0),  # æ¯è‚¡æ”¶å…¥
            'NetIncomeTTM': info.get('netIncomeToCommon', 0),  # å‡€åˆ©æ¶¦(TTM)
            'EBITDATTM': info.get('ebitda', 0),  # EBITDA(TTM)
            'TotalDebt': info.get('totalDebt', 0),  # æ€»å€ºåŠ¡
            'TotalCash': total_cash,  # æ€»ç°é‡‘
            'CashPerShare': cash_per_share,  # æ¯è‚¡ç°é‡‘
            'DebtToEquity': info.get('debtToEquity', 0),  # èµ„äº§è´Ÿå€ºç‡
            'CurrentRatio': info.get('currentRatio', 0),  # æµåŠ¨æ¯”ç‡
            'QuickRatio': info.get('quickRatio', 0),  # é€ŸåŠ¨æ¯”ç‡
            'CashFlow': info.get('operatingCashflow', 0),  # ç»è¥ç°é‡‘æµ
            
            # æ¯è‚¡æ•°æ®
            'EPS': info.get('trailingEps', 0),  # æ¯è‚¡æ”¶ç›Š
            'ForwardEPS': info.get('forwardEps', 0),  # é¢„æœŸæ¯è‚¡æ”¶ç›Š
            'BookValuePerShare': info.get('bookValue', 0),  # æ¯è‚¡å‡€èµ„äº§
            'DividendPerShare': info.get('dividendRate', 0),  # æ¯è‚¡è‚¡æ¯
            
            # è‚¡æ¯
            'DividendRate': info.get('dividendRate', 0),  # è‚¡æ¯ç‡
            'DividendYield': info.get('dividendYield', 0),  # è‚¡æ¯æ”¶ç›Šç‡
            'PayoutRatio': info.get('payoutRatio', 0),  # è‚¡æ¯æ”¯ä»˜ç‡
            'ExDividendDate': info.get('exDividendDate', 0),  # é™¤æ¯æ—¥
            
            # æˆé•¿æ€§
            'RevenueGrowth': info.get('revenueGrowth', 0),  # æ”¶å…¥å¢é•¿ç‡
            'EarningsGrowth': info.get('earningsGrowth', 0),  # ç›ˆåˆ©å¢é•¿ç‡
            'EarningsQuarterlyGrowth': info.get('earningsQuarterlyGrowth', 0),  # å­£åº¦ç›ˆåˆ©å¢é•¿
            'QuarterlyRevenueGrowth': info.get('quarterlyRevenueGrowth', 0),  # å­£åº¦æ”¶å…¥å¢é•¿
            
            # åˆ†æå¸ˆé¢„æœŸ
            'TargetPrice': info.get('targetMeanPrice', 0),  # ç›®æ ‡å¹³å‡ä»·
            'TargetHighPrice': info.get('targetHighPrice', 0),  # ç›®æ ‡é«˜ä»·
            'TargetLowPrice': info.get('targetLowPrice', 0),  # ç›®æ ‡ä½ä»·
            'ConsensusRecommendation': info.get('recommendationMean', 0),  # å…±è¯†è¯„çº§ï¼ˆæ•°å€¼ï¼‰
            'RecommendationKey': info.get('recommendationKey', ''),  # åˆ†æå¸ˆå»ºè®®ï¼ˆæ–‡å­—ï¼‰
            'NumberOfAnalystOpinions': info.get('numberOfAnalystOpinions', 0),  # åˆ†æå¸ˆæ•°é‡
            'ProjectedEPS': info.get('forwardEps', 0),  # é¢„æµ‹EPS
            'ProjectedGrowthRate': info.get('earningsQuarterlyGrowth', 0),  # é¢„æµ‹å¢é•¿ç‡
            
            # å…¶ä»–æŒ‡æ ‡
            'Beta': info.get('beta', 0),  # Betaå€¼
            'AverageVolume': info.get('averageVolume', 0),  # å¹³å‡æˆäº¤é‡
            'AverageVolume10days': info.get('averageVolume10days', 0),  # 10æ—¥å¹³å‡æˆäº¤é‡
            'FloatShares': info.get('floatShares', 0),  # æµé€šè‚¡æ•°
        }
        
        try:
            financials = ticker.financials
            if financials is not None and not financials.empty:
                fundamental['Financials'] = _format_financial_dataframe(financials)
                logger.info(f"å·²è·å–è´¢åŠ¡æŠ¥è¡¨æ•°æ®: {symbol}")
        except Exception as e:
            logger.warning(f"è·å–è´¢åŠ¡æŠ¥è¡¨å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            fundamental['Financials'] = []
        
        try:
            quarterly_financials = ticker.quarterly_financials
            if quarterly_financials is not None and not quarterly_financials.empty:
                fundamental['QuarterlyFinancials'] = _format_financial_dataframe(quarterly_financials)
                logger.info(f"å·²è·å–å­£åº¦è´¢åŠ¡æŠ¥è¡¨æ•°æ®: {symbol}")
        except Exception as e:
            logger.warning(f"è·å–å­£åº¦è´¢åŠ¡æŠ¥è¡¨å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            fundamental['QuarterlyFinancials'] = []
        
        try:
            balance_sheet = ticker.balance_sheet
            if balance_sheet is not None and not balance_sheet.empty:
                fundamental['BalanceSheet'] = _format_financial_dataframe(balance_sheet)
                logger.info(f"å·²è·å–èµ„äº§è´Ÿå€ºè¡¨æ•°æ®: {symbol}")
        except Exception as e:
            logger.warning(f"è·å–èµ„äº§è´Ÿå€ºè¡¨å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            fundamental['BalanceSheet'] = []
        
        try:
            quarterly_balance_sheet = ticker.quarterly_balance_sheet
            if quarterly_balance_sheet is not None and not quarterly_balance_sheet.empty:
                fundamental['QuarterlyBalanceSheet'] = _format_financial_dataframe(quarterly_balance_sheet)
                logger.info(f"å·²è·å–å­£åº¦èµ„äº§è´Ÿå€ºè¡¨æ•°æ®: {symbol}")
        except Exception as e:
            logger.warning(f"è·å–å­£åº¦èµ„äº§è´Ÿå€ºè¡¨å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            fundamental['QuarterlyBalanceSheet'] = []
        
        try:
            cashflow = ticker.cashflow
            if cashflow is not None and not cashflow.empty:
                fundamental['Cashflow'] = _format_financial_dataframe(cashflow)
                logger.info(f"å·²è·å–ç°é‡‘æµé‡è¡¨æ•°æ®: {symbol}")
        except Exception as e:
            logger.warning(f"è·å–ç°é‡‘æµé‡è¡¨å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            fundamental['Cashflow'] = []
        
        try:
            quarterly_cashflow = ticker.quarterly_cashflow
            if quarterly_cashflow is not None and not quarterly_cashflow.empty:
                fundamental['QuarterlyCashflow'] = _format_financial_dataframe(quarterly_cashflow)
                logger.info(f"å·²è·å–å­£åº¦ç°é‡‘æµé‡è¡¨æ•°æ®: {symbol}")
        except Exception as e:
            logger.warning(f"è·å–å­£åº¦ç°é‡‘æµé‡è¡¨å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            fundamental['QuarterlyCashflow'] = []
        
        return fundamental
        
    except Exception as e:
        logger.error(f"è·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {symbol}, é”™è¯¯: {e}")
        return None

def _get_kline_from_cache(symbol: str, interval: str, start_date: str = None):
        """
        ä»æ•°æ®åº“è·å–Kçº¿æ•°æ®
        """
        try:
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            
            if start_date:
                cursor.execute('''
                    SELECT date, open, high, low, close, volume
                    FROM kline_data
                    WHERE symbol = ? AND interval = ? AND date >= ?
                    ORDER BY date ASC
                ''', (symbol, interval, start_date))
            else:
                cursor.execute('''
                    SELECT date, open, high, low, close, volume
                    FROM kline_data
                    WHERE symbol = ? AND interval = ?
                    ORDER BY date ASC
                ''', (symbol, interval))
            
            rows = cursor.fetchall()
            conn.close()
            
            if not rows:
                return None
            
            # è½¬æ¢ä¸ºpandas DataFrame
            df = pd.DataFrame(rows, columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume'])
            df['Date'] = pd.to_datetime(df['Date'])
            df.set_index('Date', inplace=True)
            
            return df
        except Exception as e:
            logger.error(f"ä»ç¼“å­˜è·å–Kçº¿æ•°æ®å¤±è´¥: {e}")
            return None

def _save_kline_to_cache(symbol: str, interval: str, df: pd.DataFrame):
        """
        ä¿å­˜Kçº¿æ•°æ®åˆ°æ•°æ®åº“ï¼ˆå¢é‡æ›´æ–°ï¼‰
        """
        try:
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ Volume åˆ—ï¼Œå¦‚æœæ²¡æœ‰æˆ–ä¸º NaN åˆ™ä½¿ç”¨ 0
            has_volume = 'Volume' in df.columns
            
            for date, row in df.iterrows():
                date_str = date.strftime('%Y-%m-%d')
                # å¤„ç†æˆäº¤é‡æ•°æ®ï¼šå¦‚æœä¸å­˜åœ¨æˆ–ä¸º NaNï¼Œä½¿ç”¨ 0
                volume = 0
                if has_volume and pd.notna(row.get('Volume')):
                    try:
                        volume = int(row['Volume'])
                    except (ValueError, TypeError):
                        volume = 0
                
                cursor.execute('''
                    INSERT OR REPLACE INTO kline_data 
                    (symbol, interval, date, open, high, low, close, volume, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                ''', (
                    symbol,
                    interval,
                    date_str,
                    float(row['Open']),
                    float(row['High']),
                    float(row['Low']),
                    float(row['Close']),
                    volume
                ))
            
            conn.commit()
            conn.close()
            logger.info(f"Kçº¿æ•°æ®å·²ç¼“å­˜: {symbol}, {interval}, {len(df)}æ¡")
        except Exception as e:
            logger.error(f"ä¿å­˜Kçº¿æ•°æ®å¤±è´¥: {e}")

def get_historical_data(symbol: str, duration: str = '1 D', 
                           bar_size: str = '5 mins', exchange: str = '', 
                           currency: str = 'USD'):
        """
        è·å–å†å²æ•°æ®ï¼Œæ”¯æŒç¼“å­˜å’Œå¢é‡æ›´æ–°
        é»˜è®¤ç¼“å­˜è‡³å°‘1å¹´ä»¥ä¸Šæ•°æ®ï¼Œä¿è¯æ—¥æœŸè¿ç»­æ€§å’Œæœ€æ–°æ—¥æœŸä¸ºå½“æ—¥
        duration: æ•°æ®å‘¨æœŸï¼Œå¦‚ '1 D', '1 W', '1 M', '3 M', '1 Y'
        bar_size: Kçº¿å‘¨æœŸï¼Œå¦‚ '1 min', '5 mins', '1 hour', '1 day'
        """
        try:
            # è½¬æ¢bar_sizeä¸ºyfinanceæ ¼å¼
            interval_map = {
                '1 min': '1m',
                '2 mins': '2m',
                '5 mins': '5m',
                '15 mins': '15m',
                '30 mins': '30m',
                '1 hour': '1h',
                '1 day': '1d',
                '1 week': '1wk',
                '1 month': '1mo'
            }
            
            yf_interval = interval_map.get(bar_size, '1d')
            
            # å°è¯•ä»ç¼“å­˜è·å–æ•°æ®
            cached_df = _get_kline_from_cache(symbol, yf_interval)
            
            # ç»Ÿä¸€æ—¶åŒºå¤„ç†
            # è·å–å½“å‰æœ¬åœ°æ—¶é—´ï¼ˆä¸­å›½æ—¶åŒºï¼‰
            now_local = pd.Timestamp.now()
            # è½¬æ¢ä¸ºç¾å›½ä¸œéƒ¨æ—¶é—´ï¼ˆETï¼‰æ¥åˆ¤æ–­æ˜¯å¦æ˜¯äº¤æ˜“æ—¥
            import pytz
            et_tz = pytz.timezone('US/Eastern')
            now_et = now_local.tz_localize('UTC').astimezone(et_tz) if now_local.tzinfo is None else now_local.astimezone(et_tz)
            
            # ç¾è‚¡äº¤æ˜“æ—¶é—´ï¼š09:30-16:00 ET
            # å¦‚æœå½“å‰ETæ—¶é—´åœ¨æ”¶ç›˜åï¼ˆ16:00åï¼‰ï¼Œåˆ™ä»Šå¤©çš„æ•°æ®å¯ç”¨
            # å¦‚æœå½“å‰ETæ—¶é—´åœ¨å¼€ç›˜å‰ï¼ˆ09:30å‰ï¼‰ï¼Œåˆ™ä½¿ç”¨æ˜¨å¤©çš„æ•°æ®
            if now_et.hour < 16 or (now_et.hour == 16 and now_et.minute == 0):
                # å¸‚åœºæœªæ”¶ç›˜æˆ–åˆšæ”¶ç›˜ï¼Œä½¿ç”¨æ˜¨å¤©ä½œä¸ºæœ€æ–°äº¤æ˜“æ—¥
                expected_latest_date = (now_et.date() - timedelta(days=1))
            else:
                # å¸‚åœºå·²æ”¶ç›˜ï¼Œä»Šå¤©çš„æ•°æ®åº”è¯¥å¯ç”¨
                expected_latest_date = now_et.date()
            
            # è€ƒè™‘å‘¨æœ«ï¼šå¦‚æœæ˜¯å‘¨å…­/å‘¨æ—¥ï¼Œå¾€å‰æ¨åˆ°å‘¨äº”
            while expected_latest_date.weekday() >= 5:  # 5=å‘¨å…­, 6=å‘¨æ—¥
                expected_latest_date -= timedelta(days=1)
            
            today = pd.Timestamp.now().normalize().tz_localize(None)
            one_year_ago = today - timedelta(days=365)
            
            # æ£€æŸ¥ç¼“å­˜æ•°æ®çš„å®Œæ•´æ€§
            need_full_refresh = False
            
            if cached_df is None or cached_df.empty:
                # æ— ç¼“å­˜ï¼Œéœ€è¦å…¨é‡è·å–
                need_full_refresh = True
                logger.info(f"æ— ç¼“å­˜æ•°æ®ï¼Œéœ€è¦å…¨é‡è·å–: {symbol}, {yf_interval}")
            else:
                if cached_df.index.tzinfo is not None:
                    cached_df.index = cached_df.index.tz_localize(None)
                
                first_date = cached_df.index[0]
                last_date = cached_df.index[-1]
                
                if first_date > one_year_ago:
                    logger.info(f"ç¼“å­˜æ•°æ®ä¸è¶³1å¹´ï¼ˆæœ€æ—©: {first_date}ï¼‰ï¼Œéœ€è¦å…¨é‡åˆ·æ–°")
                    need_full_refresh = True
                elif last_date.date() < (today - timedelta(days=7)).date():
                    logger.info(f"ç¼“å­˜æ•°æ®è¿‡æ—§ï¼ˆæœ€æ–°: {last_date}ï¼‰ï¼Œéœ€è¦å…¨é‡åˆ·æ–°")
                    need_full_refresh = True
            
            if need_full_refresh:
                logger.info(f"ä» yfinance è·å–å…¨é‡æ•°æ®: {symbol}, 2y, {yf_interval}")
                ticker = yf.Ticker(symbol)
                df = ticker.history(period='2y', interval=yf_interval)
                
                if df.empty:
                    logger.warning(f"æ— æ³•è·å–å†å²æ•°æ®: {symbol}")
                    return None, {'code': 200, 'message': f'è¯åˆ¸ {symbol} ä¸å­˜åœ¨æˆ–æ²¡æœ‰æ•°æ®'}
                
                if 'Volume' not in df.columns:
                    logger.warning(f"è­¦å‘Š: {symbol} çš„æ•°æ®ä¸­æ²¡æœ‰ Volume åˆ—ï¼Œæˆäº¤é‡ç›¸å…³æŒ‡æ ‡å°†æ— æ³•è®¡ç®—")
                elif df['Volume'].isna().all():
                    logger.warning(f"è­¦å‘Š: {symbol} çš„æˆäº¤é‡æ•°æ®å…¨éƒ¨ä¸º NaNï¼Œæˆäº¤é‡ç›¸å…³æŒ‡æ ‡å°†æ— æ³•è®¡ç®—")
                elif df['Volume'].isna().any():
                    nan_count = df['Volume'].isna().sum()
                    logger.warning(f"è­¦å‘Š: {symbol} æœ‰ {nan_count} æ¡æ•°æ®çš„æˆäº¤é‡ä¸º NaNï¼Œå°†ä½¿ç”¨ 0 ä»£æ›¿")
                
                if df.index.tzinfo is not None:
                    df.index = df.index.tz_localize(None)
                
                _save_kline_to_cache(symbol, yf_interval, df)
                
                logger.info(f"å…¨é‡æ•°æ®å·²ç¼“å­˜: {symbol}, {yf_interval}, {len(df)}æ¡, æ—¶é—´èŒƒå›´: {df.index[0]} - {df.index[-1]}")
                return _format_historical_data(df), None
            
            last_cached_date = cached_df.index[-1]
            logger.info(f"ä½¿ç”¨ç¼“å­˜æ•°æ®å¹¶å¢é‡æ›´æ–°: {symbol}, {yf_interval}, æœ€æ–°: {last_cached_date.date()}")
            
            if last_cached_date.date() >= expected_latest_date:
                logger.info(f"ç¼“å­˜å·²æ˜¯æœ€æ–°æ•°æ®: {symbol}, ç¼“å­˜æ—¥æœŸ={last_cached_date.date()}, é¢„æœŸæœ€æ–°={expected_latest_date}")
                return _format_historical_data(cached_df), None
            
            try:
                ticker = yf.Ticker(symbol)
                new_data = ticker.history(period='10d', interval=yf_interval)
                
                if not new_data.empty:
                    if new_data.index.tzinfo is not None:
                        new_data.index = new_data.index.tz_localize(None)
                    
                    new_data_filtered = new_data[new_data.index > last_cached_date]
                    
                    if not new_data_filtered.empty:
                        combined_df = pd.concat([cached_df, new_data])
                        combined_df = combined_df[~combined_df.index.duplicated(keep='last')]
                        combined_df = combined_df.sort_index()
                        
                        _save_kline_to_cache(symbol, yf_interval, new_data)
                        
                        logger.info(f"å¢é‡æ›´æ–°å®Œæˆ: {symbol}, æ–°å¢{len(new_data_filtered)}æ¡, æ€»è®¡{len(combined_df)}æ¡, æœ€æ–°: {combined_df.index[-1].date()}")
                        return _format_historical_data(combined_df), None
                    else:
                        # æ— æ–°æ•°æ®ï¼Œå¯èƒ½æ˜¯éäº¤æ˜“æ—¥æˆ–æ—¶åŒºåŸå› 
                        logger.info(f"æ— æ–°æ•°æ®ï¼Œè¿”å›ç¼“å­˜æ•°æ®: {symbol}, ç¼“å­˜æœ€æ–°æ—¥æœŸ: {last_cached_date.date()}")
                        return _format_historical_data(cached_df), None
                else:
                    logger.info(f"è·å–æœ€æ–°æ•°æ®ä¸ºç©ºï¼Œè¿”å›ç¼“å­˜æ•°æ®")
                    return _format_historical_data(cached_df), None
                    
            except Exception as e:
                logger.warning(f"å¢é‡æ›´æ–°å¤±è´¥: {e}ï¼Œè¿”å›ç¼“å­˜æ•°æ®")
            
            return _format_historical_data(cached_df), None
            
        except Exception as e:
            logger.error(f"è·å–å†å²æ•°æ®å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            return None, {'code': 500, 'message': str(e)}

def _format_historical_data(df: pd.DataFrame):
        """
        æ ¼å¼åŒ–å†å²æ•°æ®
        """
        result = []
        # æ£€æŸ¥æ˜¯å¦æœ‰ Volume åˆ—ï¼Œå¦‚æœæ²¡æœ‰æˆ–ä¸º NaN åˆ™ä½¿ç”¨ 0
        has_volume = 'Volume' in df.columns
        
        for date, row in df.iterrows():
            date_str = date.strftime('%Y%m%d')
            if pd.notna(date.hour):  # å¦‚æœæœ‰æ—¶é—´
                date_str = date.strftime('%Y%m%d %H:%M:%S')
            
            # å¤„ç†æˆäº¤é‡æ•°æ®ï¼šå¦‚æœä¸å­˜åœ¨æˆ–ä¸º NaNï¼Œä½¿ç”¨ 0
            volume = 0
            if has_volume and pd.notna(row.get('Volume')):
                try:
                    volume = int(row['Volume'])
                except (ValueError, TypeError):
                    volume = 0
            
            result.append({
                'date': date_str,
                'open': float(row['Open']),
                'high': float(row['High']),
                'low': float(row['Low']),
                'close': float(row['Close']),
                'volume': volume,
                'average': float((row['High'] + row['Low'] + row['Close']) / 3),
                'barCount': 1
            })
        
        return result

def calculate_technical_indicators(symbol: str, duration: str = '1 M', bar_size: str = '1 day'):
        """
        è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆåŸºäºå†å²æ•°æ®ï¼‰
        è¿”å›ï¼šç§»åŠ¨å¹³å‡çº¿ã€RSIã€MACDç­‰
        å¦‚æœè¯åˆ¸ä¸å­˜åœ¨ï¼Œè¿”å›(None, error_info)
        """
        hist_data, error = get_historical_data(symbol, duration, bar_size)
        
        if error:
            return None, error
        
        if not hist_data or len(hist_data) < 20:
            logger.warning(f"æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: {symbol}")
            return None, None
        
        closes = np.array([bar['close'] for bar in hist_data])
        highs = np.array([bar['high'] for bar in hist_data])
        lows = np.array([bar['low'] for bar in hist_data])
        volumes = np.array([bar['volume'] for bar in hist_data])
        
        valid_volumes = volumes[volumes > 0]
        if len(valid_volumes) == 0:
            logger.warning(f"è­¦å‘Š: {symbol} æ‰€æœ‰æˆäº¤é‡æ•°æ®ä¸º 0ï¼Œæˆäº¤é‡ç›¸å…³æŒ‡æ ‡å°†æ— æ³•æ­£å¸¸è®¡ç®—")
        
        result = {
            'symbol': symbol,
            'current_price': float(closes[-1]),
            'data_points': int(len(closes)),
        }
        
        # 1. ç§»åŠ¨å¹³å‡çº¿ (MA)
        ma_data = calculate_ma(closes)
        result.update(ma_data)
            
        # 2. RSI (ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡)
        rsi_data = calculate_rsi(closes)
        result.update(rsi_data)
                
        # 3. å¸ƒæ—å¸¦ (Bollinger Bands)
        bb_data = calculate_bollinger(closes)
        result.update(bb_data)
            
        # 4. MACD
        macd_data = calculate_macd(closes)
        result.update(macd_data)
                    
        # 5. æˆäº¤é‡åˆ†æ
        volume_data = calculate_volume(volumes)
        result.update(volume_data)
            
        # 6. ä»·æ ¼å˜åŒ–
        price_change_data = calculate_price_change(closes)
        result.update(price_change_data)
            
        # 7. æ³¢åŠ¨ç‡
        volatility_data = calculate_volatility(closes)
        result.update(volatility_data)
            
        # 8. æ”¯æŒä½å’Œå‹åŠ›ä½
        support_resistance = calculate_support_resistance(closes, highs, lows)
        result.update(support_resistance)
        
        # 9. KDJæŒ‡æ ‡ï¼ˆéšæœºæŒ‡æ ‡ï¼‰
        if len(closes) >= 9:
            kdj = calculate_kdj(closes, highs, lows)
            result.update(kdj)
        
        # 10. ATRï¼ˆå¹³å‡çœŸå®æ³¢å¹…ï¼‰
        if len(closes) >= 14:
            atr = calculate_atr(closes, highs, lows)
            result['atr'] = atr
            result['atr_percent'] = float((atr / closes[-1]) * 100)
        
        # 11. å¨å»‰æŒ‡æ ‡ï¼ˆWilliams %Rï¼‰
        if len(closes) >= 14:
            wr = calculate_williams_r(closes, highs, lows)
            result['williams_r'] = wr
        
        # 12. OBVï¼ˆèƒ½é‡æ½®æŒ‡æ ‡ï¼‰
        if len(volumes) >= 20:
            obv = calculate_obv(closes, volumes)
            result['obv_current'] = float(obv[-1]) if len(obv) > 0 else 0.0
            result['obv_trend'] = get_trend(obv[-10:]) if len(obv) >= 10 else 'neutral'
        
        # 13. è¶‹åŠ¿å¼ºåº¦
        trend_info = analyze_trend_strength(closes, highs, lows)
        result.update(trend_info)

        # 14. æ–æ³¢é‚£å¥‘å›æ’¤ä½
        fibonacci_levels = calculate_fibonacci_retracement(highs, lows)
        result.update(fibonacci_levels)

        # 15. ç¼ è®ºåˆ†æï¼ˆå·²ä¼˜åŒ–ï¼ŒåŒ…å«æˆäº¤é‡åˆ†æï¼‰
        # æå–æ—¶é—´æ•°æ®ç”¨äºç¼ è®ºåˆ†æï¼ˆåªæ˜¾ç¤ºæ—¥æœŸï¼Œä¸æ˜¾ç¤ºæ—¶åˆ†ç§’ï¼‰
        times = None
        if hist_data:
            times = []
            for bar in hist_data:
                date_str = bar.get('date', '')
                try:
                    # è½¬æ¢æ—¶é—´æ ¼å¼ï¼šYYYYMMDD -> YYYY-MM-DD
                    if len(date_str) == 8:
                        times.append(f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}")
                    elif ' ' in date_str:
                        # å¦‚æœæœ‰æ—¶åˆ†ç§’ï¼Œåªæå–æ—¥æœŸéƒ¨åˆ†
                        dt = datetime.strptime(date_str, '%Y%m%d %H:%M:%S')
                        times.append(dt.strftime('%Y-%m-%d'))
                    else:
                        times.append(date_str)
                except Exception:
                    times.append(date_str)
        
        chanlun_data = calculate_chanlun_analysis(closes, highs, lows, volumes, times=times)
        
        # è¿‡æ»¤ï¼šåªä¿ç•™ä¸€ä¸ªæœˆå†…çš„ä¸­æ¢ã€ä¹°å…¥ç‚¹å’Œå–å‡ºç‚¹
        one_month_ago = (datetime.now() - timedelta(days=30)).date()
        
        # è¿‡æ»¤ä¸­æ¢
        if 'central_banks' in chanlun_data and chanlun_data['central_banks']:
            filtered_central_banks = []
            for cb in chanlun_data['central_banks']:
                # æ£€æŸ¥ç»“æŸæ—¶é—´æ˜¯å¦åœ¨ä¸€ä¸ªæœˆå†…
                if cb.get('end_time'):
                    try:
                        end_date = datetime.strptime(cb['end_time'], '%Y-%m-%d').date()
                        if end_date >= one_month_ago:
                            filtered_central_banks.append(cb)
                    except Exception:
                        # å¦‚æœæ—¶é—´è§£æå¤±è´¥ï¼Œä¿ç•™è¯¥ä¸­æ¢
                        filtered_central_banks.append(cb)
                else:
                    # å¦‚æœæ²¡æœ‰æ—¶é—´ä¿¡æ¯ï¼Œæ ¹æ®ç´¢å¼•åˆ¤æ–­ï¼ˆå‡è®¾æ˜¯æœ€è¿‘çš„æ•°æ®ï¼‰
                    if cb.get('end_index', 0) >= len(closes) - 30:
                        filtered_central_banks.append(cb)
            chanlun_data['central_banks'] = filtered_central_banks
        
        # è¿‡æ»¤ä¹°å…¥ç‚¹
        if 'trading_points' in chanlun_data and 'buy_points' in chanlun_data['trading_points']:
            filtered_buy_points = []
            for bp in chanlun_data['trading_points']['buy_points']:
                if bp.get('time'):
                    try:
                        point_date = datetime.strptime(bp['time'], '%Y-%m-%d').date()
                        if point_date >= one_month_ago:
                            filtered_buy_points.append(bp)
                    except Exception:
                        # å¦‚æœæ—¶é—´è§£æå¤±è´¥ï¼Œæ ¹æ®ç´¢å¼•åˆ¤æ–­
                        if bp.get('index', 0) >= len(closes) - 30:
                            filtered_buy_points.append(bp)
                else:
                    # å¦‚æœæ²¡æœ‰æ—¶é—´ä¿¡æ¯ï¼Œæ ¹æ®ç´¢å¼•åˆ¤æ–­
                    if bp.get('index', 0) >= len(closes) - 30:
                        filtered_buy_points.append(bp)
            chanlun_data['trading_points']['buy_points'] = filtered_buy_points
        
        # è¿‡æ»¤å–å‡ºç‚¹
        if 'trading_points' in chanlun_data and 'sell_points' in chanlun_data['trading_points']:
            filtered_sell_points = []
            for sp in chanlun_data['trading_points']['sell_points']:
                if sp.get('time'):
                    try:
                        point_date = datetime.strptime(sp['time'], '%Y-%m-%d').date()
                        if point_date >= one_month_ago:
                            filtered_sell_points.append(sp)
                    except Exception:
                        # å¦‚æœæ—¶é—´è§£æå¤±è´¥ï¼Œæ ¹æ®ç´¢å¼•åˆ¤æ–­
                        if sp.get('index', 0) >= len(closes) - 30:
                            filtered_sell_points.append(sp)
                else:
                    # å¦‚æœæ²¡æœ‰æ—¶é—´ä¿¡æ¯ï¼Œæ ¹æ®ç´¢å¼•åˆ¤æ–­
                    if sp.get('index', 0) >= len(closes) - 30:
                        filtered_sell_points.append(sp)
            chanlun_data['trading_points']['sell_points'] = filtered_sell_points
        
        result.update(chanlun_data)
        
        # 16. CCIï¼ˆé¡ºåŠ¿æŒ‡æ ‡ï¼‰
        if len(closes) >= 14:
            cci_data = calculate_cci(closes, highs, lows)
            result.update(cci_data)
        
        # 17. ADXï¼ˆå¹³å‡è¶‹å‘æŒ‡æ ‡ï¼‰
        if len(closes) >= 28:  # ADXéœ€è¦period*2çš„æ•°æ®
            adx_data = calculate_adx(closes, highs, lows)
            result.update(adx_data)
        
        # 18. VWAPï¼ˆæˆäº¤é‡åŠ æƒå¹³å‡ä»·ï¼‰
        # æŒ‰ç…§ Futu å…¬å¼ï¼šAVGPRICE=TOTALAMOUNT/TOTALVOL, å¦åˆ™ä½¿ç”¨(C+H+L)/3
        # ä½¿ç”¨è¾ƒé•¿å‘¨æœŸï¼ˆ80å¤©ï¼‰ä»¥æ›´æ¥è¿‘ Futu çš„è®¡ç®—ç»“æœ
        if len(closes) >= 1:
            # ä½¿ç”¨80å¤©å‘¨æœŸä»¥æ›´æ¥è¿‘ Futuï¼Œå¦‚æœæ•°æ®ä¸è¶³åˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ•°æ®
            vwap_period = min(80, len(closes)) if len(closes) >= 80 else None
            vwap_data = calculate_vwap(closes, highs, lows, volumes, period=vwap_period)
            result.update(vwap_data)
        
        # 19. SARï¼ˆæŠ›ç‰©çº¿è½¬å‘æŒ‡æ ‡ï¼‰
        if len(closes) >= 10:
            sar_data = calculate_sar(closes, highs, lows)
            result.update(sar_data)

        # 21. SuperTrend (è¶…çº§è¶‹åŠ¿)
        if len(closes) >= 11:
            st_data = calculate_supertrend(closes, highs, lows)
            result.update(st_data)
            
        # 22. StochRSI (éšæœºç›¸å¯¹å¼ºå¼±æŒ‡æ ‡)
        if len(closes) >= 28:
            stoch_rsi_data = calculate_stoch_rsi(closes)
            result.update(stoch_rsi_data)
            
        # 23. Volume Profile (æˆäº¤é‡åˆ†å¸ƒ)
        if len(closes) >= 20:
            vp_data = calculate_volume_profile(closes, highs, lows, volumes)
            result.update(vp_data)

        # 24. Ichimoku Cloud (ä¸€ç›®å‡è¡¡è¡¨)
        if len(closes) >= 52:
            ichimoku_data = calculate_ichimoku(closes, highs, lows)
            result.update(ichimoku_data)
        
        # 25. MLé¢„æµ‹ï¼ˆæœºå™¨å­¦ä¹ é¢„æµ‹ï¼ŒåŒ…å«æˆäº¤é‡åˆ†æï¼‰
        if len(closes) >= 20 and len(valid_volumes) > 0:
            ml_data = calculate_ml_predictions(closes, highs, lows, volumes)
            result.update(ml_data)

        # 26. è·å–åŸºæœ¬é¢æ•°æ®
        try:
            fundamental_data = get_fundamental_data(symbol)
            if fundamental_data:
                result['fundamental_data'] = fundamental_data
                logger.info(f"å·²è·å–åŸºæœ¬é¢æ•°æ®: {symbol}")
        except Exception as e:
            logger.warning(f"è·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            result['fundamental_data'] = None
            
        return result, None  # è¿”å›ç»“æœå’Œé”™è¯¯ä¿¡æ¯ï¼ˆæ— é”™è¯¯ä¸ºNoneï¼‰

def generate_signals(indicators: dict):
        """
        åŸºäºæŠ€æœ¯æŒ‡æ ‡ç”Ÿæˆä¹°å–ä¿¡å·
        """
        if not indicators:
            return None
            
        signals = {
            'symbol': indicators.get('symbol'),
            'current_price': indicators.get('current_price'),
            'signals': [],
            'score': 0,  # ç»¼åˆè¯„åˆ† (-100 to 100)
        }
        
        # 1. MAäº¤å‰ä¿¡å·
        if 'ma5' in indicators and 'ma20' in indicators:
            if indicators['ma5'] > indicators['ma20']:
                signals['signals'].append('ğŸ“ˆ çŸ­æœŸå‡çº¿(MA5)åœ¨é•¿æœŸå‡çº¿(MA20)ä¹‹ä¸Š - çœ‹æ¶¨')
                signals['score'] += 15
            else:
                signals['signals'].append('ğŸ“‰ çŸ­æœŸå‡çº¿(MA5)åœ¨é•¿æœŸå‡çº¿(MA20)ä¹‹ä¸‹ - çœ‹è·Œ')
                signals['score'] -= 15
                
        # 2. RSIè¶…ä¹°è¶…å–
        if 'rsi' in indicators:
            rsi = indicators['rsi']
            if rsi < 30:
                signals['signals'].append(f'ğŸŸ¢ RSI={rsi:.1f} è¶…å–åŒºåŸŸ - å¯èƒ½åå¼¹')
                signals['score'] += 25
            elif rsi > 70:
                signals['signals'].append(f'ğŸ”´ RSI={rsi:.1f} è¶…ä¹°åŒºåŸŸ - å¯èƒ½å›è°ƒ')
                signals['score'] -= 25
            else:
                signals['signals'].append(f'âšª RSI={rsi:.1f} ä¸­æ€§åŒºåŸŸ')
                
        # 3. å¸ƒæ—å¸¦
        if all(k in indicators for k in ['bb_upper', 'bb_lower', 'current_price']):
            price = indicators['current_price']
            upper = indicators['bb_upper']
            lower = indicators['bb_lower']
            
            if price <= lower:
                signals['signals'].append('ğŸŸ¢ ä»·æ ¼è§¦åŠå¸ƒæ—å¸¦ä¸‹è½¨ - å¯èƒ½åå¼¹')
                signals['score'] += 20
            elif price >= upper:
                signals['signals'].append('ğŸ”´ ä»·æ ¼è§¦åŠå¸ƒæ—å¸¦ä¸Šè½¨ - å¯èƒ½å›è°ƒ')
                signals['score'] -= 20
                
        # 4. MACD
        if 'macd_histogram' in indicators:
            histogram = indicators['macd_histogram']
            if histogram > 0:
                signals['signals'].append('ğŸ“ˆ MACDæŸ±çŠ¶å›¾ä¸ºæ­£ - çœ‹æ¶¨')
                signals['score'] += 10
            else:
                signals['signals'].append('ğŸ“‰ MACDæŸ±çŠ¶å›¾ä¸ºè´Ÿ - çœ‹è·Œ')
                signals['score'] -= 10
                
        # 5. æˆäº¤é‡åˆ†æï¼ˆå¢å¼ºç‰ˆï¼‰
        if 'volume_ratio' in indicators:
            ratio = indicators['volume_ratio']
            if ratio > 1.5:
                signals['signals'].append(f'ğŸ“Š æˆäº¤é‡æ”¾å¤§{ratio:.1f}å€ - è¶‹åŠ¿åŠ å¼º')
                signals['score'] += 10
            elif ratio < 0.5:
                signals['signals'].append(f'ğŸ“Š æˆäº¤é‡èç¼© - è¶‹åŠ¿å‡å¼±')
        
        # 5.1 ä»·é‡é…åˆåˆ†æ
        if 'price_volume_confirmation' in indicators:
            confirmation = indicators['price_volume_confirmation']
            if confirmation == 'bullish':
                signals['signals'].append('âœ… ä»·æ¶¨é‡å¢ - çœ‹æ¶¨ç¡®è®¤ï¼Œè¶‹åŠ¿å¥åº·')
                signals['score'] += 15
            elif confirmation == 'bearish':
                signals['signals'].append('âŒ ä»·è·Œé‡å¢ - çœ‹è·Œç¡®è®¤ï¼Œä¸‹è·ŒåŠ¨èƒ½å¼º')
                signals['score'] -= 15
            elif confirmation == 'divergence':
                signals['signals'].append('âš ï¸ ä»·é‡èƒŒç¦» - è¶‹åŠ¿å¯èƒ½åè½¬ï¼Œéœ€è°¨æ…')
                signals['score'] -= 10
        
        # 5.2 æˆäº¤é‡ä¿¡å·
        if 'volume_signal' in indicators:
            vol_signal = indicators['volume_signal']
            if vol_signal == 'high_volume':
                vol_ratio = indicators.get('volume_ratio', 1.0)
                signals['signals'].append(f'ğŸ”¥ é«˜æˆäº¤é‡ä¿¡å· - å½“å‰æˆäº¤é‡æ˜¯å‡é‡çš„{vol_ratio:.1f}å€')
            elif vol_signal == 'low_volume':
                signals['signals'].append('ğŸ’¤ ä½æˆäº¤é‡ä¿¡å· - å¸‚åœºå‚ä¸åº¦ä½ï¼Œè¶‹åŠ¿å¯èƒ½ä¸ç¨³å›º')
        
        # 5.3 OBVè¶‹åŠ¿ç¡®è®¤
        if 'obv_trend' in indicators:
            obv_trend = indicators['obv_trend']
            if obv_trend == 'up':
                signals['signals'].append('ğŸ“ˆ OBVä¸Šå‡è¶‹åŠ¿ - èµ„é‡‘æµå…¥ï¼Œçœ‹æ¶¨')
                signals['score'] += 10
            elif obv_trend == 'down':
                signals['signals'].append('ğŸ“‰ OBVä¸‹é™è¶‹åŠ¿ - èµ„é‡‘æµå‡ºï¼Œçœ‹è·Œ')
                signals['score'] -= 10
        
        # 5.4 VWAPä½ç½®ç¡®è®¤
        if 'vwap' in indicators and 'current_price' in indicators:
            vwap = indicators['vwap']
            price = indicators['current_price']
            if price > vwap:
                deviation = indicators.get('vwap_deviation', 0)
                signals['signals'].append(f'âœ… ä»·æ ¼åœ¨VWAPä¹‹ä¸Š(åç¦»{deviation:.1f}%) - å¤šå¤´å ä¼˜')
                signals['score'] += 8
            else:
                deviation = indicators.get('vwap_deviation', 0)
                signals['signals'].append(f'âŒ ä»·æ ¼åœ¨VWAPä¹‹ä¸‹(åç¦»{deviation:.1f}%) - ç©ºå¤´å ä¼˜')
                signals['score'] -= 8
                
        # 6. æ³¢åŠ¨ç‡
        if 'volatility_20' in indicators:
            vol = indicators['volatility_20']
            if vol > 3:
                signals['signals'].append(f'âš ï¸ é«˜æ³¢åŠ¨ç‡{vol:.1f}% - é£é™©è¾ƒå¤§')
            elif vol < 1:
                signals['signals'].append(f'âœ… ä½æ³¢åŠ¨ç‡{vol:.1f}% - ç›¸å¯¹ç¨³å®š')
        
        # 7. æ”¯æ’‘ä½å’Œå‹åŠ›ä½åˆ†æ
        current_price = indicators.get('current_price')
        if current_price:
            # æ£€æŸ¥æ˜¯å¦æ¥è¿‘å…³é”®æ”¯æ’‘ä½
            support_keys = [k for k in indicators.keys() if 'support' in k.lower()]
            resistance_keys = [k for k in indicators.keys() if 'resistance' in k.lower()]
            
            # æ‰¾æœ€è¿‘çš„æ”¯æ’‘ä½
            nearest_support = None
            nearest_support_dist = float('inf')
            for key in support_keys:
                support = indicators[key]
                if support < current_price:
                    dist = current_price - support
                    dist_pct = (dist / current_price) * 100
                    if dist_pct < nearest_support_dist:
                        nearest_support = support
                        nearest_support_dist = dist_pct
            
            # æ‰¾æœ€è¿‘çš„å‹åŠ›ä½
            nearest_resistance = None
            nearest_resistance_dist = float('inf')
            for key in resistance_keys:
                resistance = indicators[key]
                if resistance > current_price:
                    dist = resistance - current_price
                    dist_pct = (dist / current_price) * 100
                    if dist_pct < nearest_resistance_dist:
                        nearest_resistance = resistance
                        nearest_resistance_dist = dist_pct
            
            # æ ¹æ®æ”¯æ’‘å‹åŠ›ä½ç½®ç»™å‡ºä¿¡å·
            if nearest_support and nearest_support_dist < 2:
                signals['signals'].append(f'ğŸŸ¢ æ¥è¿‘æ”¯æ’‘ä½${nearest_support:.2f} (è·ç¦»{nearest_support_dist:.1f}%) - å¯èƒ½åå¼¹')
                signals['score'] += 15
            
            if nearest_resistance and nearest_resistance_dist < 2:
                signals['signals'].append(f'ğŸ”´ æ¥è¿‘å‹åŠ›ä½${nearest_resistance:.2f} (è·ç¦»{nearest_resistance_dist:.1f}%) - å¯èƒ½å›è°ƒ')
                signals['score'] -= 15
            
            # çªç ´ä¿¡å·
            if 'resistance_20d_high' in indicators:
                high_20 = indicators['resistance_20d_high']
                if current_price >= high_20 * 0.99:  # æ¥è¿‘æˆ–çªç ´20æ—¥é«˜ç‚¹
                    signals['signals'].append(f'ğŸš€ çªç ´20æ—¥é«˜ç‚¹${high_20:.2f} - å¼ºåŠ¿ä¿¡å·')
                    signals['score'] += 20
            
            if 'support_20d_low' in indicators:
                low_20 = indicators['support_20d_low']
                if current_price <= low_20 * 1.01:  # æ¥è¿‘æˆ–è·Œç ´20æ—¥ä½ç‚¹
                    signals['signals'].append(f'âš ï¸ è·Œç ´20æ—¥ä½ç‚¹${low_20:.2f} - å¼±åŠ¿ä¿¡å·')
                    signals['score'] -= 20
        
        # 8. KDJæŒ‡æ ‡
        if all(k in indicators for k in ['kdj_k', 'kdj_d', 'kdj_j']):
            k_val = indicators['kdj_k']
            d_val = indicators['kdj_d']
            j_val = indicators['kdj_j']
            
            if j_val < 20:
                signals['signals'].append(f'ğŸŸ¢ KDJè¶…å–(J={j_val:.1f}) - çŸ­çº¿ä¹°å…¥æœºä¼š')
                signals['score'] += 15
            elif j_val > 80:
                signals['signals'].append(f'ğŸ”´ KDJè¶…ä¹°(J={j_val:.1f}) - çŸ­çº¿å–å‡ºä¿¡å·')
                signals['score'] -= 15
            
            # é‡‘å‰æ­»å‰
            if k_val > d_val and k_val < 50:
                signals['signals'].append(f'ğŸ“ˆ KDJé‡‘å‰ - çœ‹æ¶¨')
                signals['score'] += 10
            elif k_val < d_val and k_val > 50:
                signals['signals'].append(f'ğŸ“‰ KDJæ­»å‰ - çœ‹è·Œ')
                signals['score'] -= 10
        
        # 9. å¨å»‰æŒ‡æ ‡
        if 'williams_r' in indicators:
            wr = indicators['williams_r']
            if wr < -80:
                signals['signals'].append(f'ğŸŸ¢ å¨å»‰æŒ‡æ ‡è¶…å–(WR={wr:.1f}) - åå¼¹æ¦‚ç‡å¤§')
                signals['score'] += 12
            elif wr > -20:
                signals['signals'].append(f'ğŸ”´ å¨å»‰æŒ‡æ ‡è¶…ä¹°(WR={wr:.1f}) - å›è°ƒæ¦‚ç‡å¤§')
                signals['score'] -= 12
        
        # 10. OBVè¶‹åŠ¿
        if 'obv_trend' in indicators:
            obv_trend = indicators['obv_trend']
            price_change = indicators.get('price_change_pct', 0)
            
            if obv_trend == 'up' and price_change > 0:
                signals['signals'].append('ğŸ“Š é‡ä»·é½å‡ - å¼ºåŠ¿ä¸Šæ¶¨ä¿¡å·')
                signals['score'] += 15
            elif obv_trend == 'down' and price_change < 0:
                signals['signals'].append('ğŸ“Š é‡ä»·é½è·Œ - å¼±åŠ¿ä¸‹è·Œä¿¡å·')
                signals['score'] -= 15
            elif obv_trend == 'up' and price_change < 0:
                signals['signals'].append('âš ï¸ é‡ä»·èƒŒç¦»(ä»·è·Œé‡å‡) - å¯èƒ½è§åº•')
                signals['score'] += 8
            elif obv_trend == 'down' and price_change > 0:
                signals['signals'].append('âš ï¸ é‡ä»·èƒŒç¦»(ä»·æ¶¨é‡è·Œ) - å¯èƒ½è§é¡¶')
                signals['score'] -= 8
        
        # 11. è¶‹åŠ¿å¼ºåº¦åˆ†æ
        if 'trend_strength' in indicators:
            strength = indicators['trend_strength']
            direction = indicators.get('trend_direction', 'neutral')
            
            if strength > 50:
                if direction == 'up':
                    signals['signals'].append(f'ğŸš€ å¼ºåŠ¿ä¸Šæ¶¨è¶‹åŠ¿(å¼ºåº¦{strength:.0f}%) - é¡ºåŠ¿åšå¤š')
                    signals['score'] += 18
                elif direction == 'down':
                    signals['signals'].append(f'âš ï¸ å¼ºåŠ¿ä¸‹è·Œè¶‹åŠ¿(å¼ºåº¦{strength:.0f}%) - è§‚æœ›æˆ–åšç©º')
                    signals['score'] -= 18
            elif strength < 25:
                signals['signals'].append(f'ğŸ“Š è¶‹åŠ¿ä¸æ˜æ˜¾(å¼ºåº¦{strength:.0f}%) - éœ‡è¡è¡Œæƒ…')
        
        # 12. è¿ç»­æ¶¨è·Œåˆ†æ
        if 'consecutive_up_days' in indicators and 'consecutive_down_days' in indicators:
            up_days = indicators['consecutive_up_days']
            down_days = indicators['consecutive_down_days']
            
            if up_days >= 5:
                signals['signals'].append(f'âš ï¸ è¿ç»­ä¸Šæ¶¨{up_days}å¤© - æ³¨æ„è·åˆ©å›åé£é™©')
                signals['score'] -= 10
            elif down_days >= 5:
                signals['signals'].append(f'ğŸŸ¢ è¿ç»­ä¸‹è·Œ{down_days}å¤© - å¯èƒ½å‡ºç°åå¼¹')
                signals['score'] += 10
            elif up_days >= 3:
                signals['signals'].append(f'ğŸ“ˆ è¿ç»­ä¸Šæ¶¨{up_days}å¤© - çŸ­æœŸå¼ºåŠ¿')
            elif down_days >= 3:
                signals['signals'].append(f'ğŸ“‰ è¿ç»­ä¸‹è·Œ{down_days}å¤© - çŸ­æœŸå¼±åŠ¿')
        
        # 13. ATRé£é™©æç¤º
        if 'atr_percent' in indicators:
            atr_pct = indicators['atr_percent']
            if atr_pct > 5:
                signals['signals'].append(f'âš¡ é«˜æ³¢åŠ¨(ATR {atr_pct:.1f}%) - å»ºè®®ç¼©å°ä»“ä½')
            elif atr_pct < 1.5:
                signals['signals'].append(f'âœ… ä½æ³¢åŠ¨(ATR {atr_pct:.1f}%) - é€‚åˆæŒä»“')
        
        # 14. CCIé¡ºåŠ¿æŒ‡æ ‡
        if 'cci' in indicators:
            cci = indicators['cci']
            cci_signal = indicators.get('cci_signal', 'neutral')
            if cci_signal == 'overbought':
                if cci > 200:
                    signals['signals'].append(f'ğŸ”´ CCI={cci:.1f} æåº¦è¶…ä¹° - å¼ºçƒˆå›è°ƒä¿¡å·')
                    signals['score'] -= 22
                else:
                    signals['signals'].append(f'ğŸ”´ CCI={cci:.1f} è¶…ä¹°åŒºåŸŸ - å¯èƒ½å›è°ƒ')
                    signals['score'] -= 18
            elif cci_signal == 'oversold':
                if cci < -200:
                    signals['signals'].append(f'ğŸŸ¢ CCI={cci:.1f} æåº¦è¶…å– - å¼ºçƒˆåå¼¹ä¿¡å·')
                    signals['score'] += 22
                else:
                    signals['signals'].append(f'ğŸŸ¢ CCI={cci:.1f} è¶…å–åŒºåŸŸ - å¯èƒ½åå¼¹')
                    signals['score'] += 18
        
        # 15. ADXè¶‹åŠ¿å¼ºåº¦
        if 'adx' in indicators:
            adx = indicators['adx']
            adx_signal = indicators.get('adx_signal', 'weak_trend')
            plus_di = indicators.get('plus_di', 0)
            minus_di = indicators.get('minus_di', 0)
            
            if adx_signal == 'strong_trend':
                if plus_di > minus_di:
                    if adx > 40:
                        signals['signals'].append(f'ğŸš€ ADX={adx:.1f} æå¼ºä¸Šæ¶¨è¶‹åŠ¿(+DI={plus_di:.1f}) - å¼ºçƒˆçœ‹å¤š')
                        signals['score'] += 25
                    else:
                        signals['signals'].append(f'ğŸ“ˆ ADX={adx:.1f} å¼ºåŠ¿ä¸Šæ¶¨è¶‹åŠ¿(+DI={plus_di:.1f}) - é¡ºåŠ¿åšå¤š')
                        signals['score'] += 20
                else:
                    if adx > 40:
                        signals['signals'].append(f'âš ï¸ ADX={adx:.1f} æå¼ºä¸‹è·Œè¶‹åŠ¿(-DI={minus_di:.1f}) - å¼ºçƒˆçœ‹ç©º')
                        signals['score'] -= 25
                    else:
                        signals['signals'].append(f'ğŸ“‰ ADX={adx:.1f} å¼ºåŠ¿ä¸‹è·Œè¶‹åŠ¿(-DI={minus_di:.1f}) - è§‚æœ›æˆ–åšç©º')
                        signals['score'] -= 20
            elif adx_signal == 'trend':
                if plus_di > minus_di:
                    signals['signals'].append(f'ğŸ“ˆ ADX={adx:.1f} ä¸­ç­‰ä¸Šæ¶¨è¶‹åŠ¿ - å¯å…³æ³¨')
                    signals['score'] += 8
                else:
                    signals['signals'].append(f'ğŸ“‰ ADX={adx:.1f} ä¸­ç­‰ä¸‹è·Œè¶‹åŠ¿ - è°¨æ…')
                    signals['score'] -= 8
            else:
                signals['signals'].append(f'ğŸ“Š ADX={adx:.1f} æ— æ˜æ˜¾è¶‹åŠ¿ - éœ‡è¡è¡Œæƒ…')
        
        # 16. VWAPä»·æ ¼ä½ç½®ï¼ˆæœºæ„æˆæœ¬çº¿åˆ†æï¼‰
        if 'vwap' in indicators and 'current_price' in indicators:
            vwap = indicators['vwap']
            current_price = indicators['current_price']
            vwap_deviation = indicators.get('vwap_deviation', 0)
            vwap_signal = indicators.get('vwap_signal', 'at')
            
            if vwap_signal == 'above':
                if vwap_deviation > 3:
                    signals['signals'].append(f'ğŸ’° ä»·æ ¼è¿œé«˜äºVWAP(${vwap:.2f}, +{vwap_deviation:.1f}%) - å¼ºåŠ¿å¤šå¤´')
                    signals['score'] += 15
                else:
                    signals['signals'].append(f'ğŸ“ˆ ä»·æ ¼åœ¨VWAP(${vwap:.2f}, +{vwap_deviation:.1f}%)ä¹‹ä¸Š - å¤šå¤´ä¿¡å·')
                    signals['score'] += 12
            elif vwap_signal == 'below':
                if vwap_deviation < -3:
                    signals['signals'].append(f'ğŸ“‰ ä»·æ ¼è¿œä½äºVWAP(${vwap:.2f}, {vwap_deviation:.1f}%) - å¼±åŠ¿ç©ºå¤´')
                    signals['score'] -= 15
                else:
                    signals['signals'].append(f'ğŸ“‰ ä»·æ ¼åœ¨VWAP(${vwap:.2f}, {vwap_deviation:.1f}%)ä¹‹ä¸‹ - ç©ºå¤´ä¿¡å·')
                    signals['score'] -= 12
            else:
                signals['signals'].append(f'âš–ï¸ ä»·æ ¼ç­‰äºVWAP(${vwap:.2f}) - å¹³è¡¡çŠ¶æ€')
        
        # 17. SARè½¬å‘ä¿¡å·ï¼ˆæŠ›ç‰©çº¿æ­¢æŸï¼‰
        if 'sar' in indicators:
            sar = indicators['sar']
            sar_signal = indicators.get('sar_signal', 'hold')
            sar_trend = indicators.get('sar_trend', 'neutral')
            sar_distance = indicators.get('sar_distance_pct', 0)
            
            if sar_signal == 'buy':
                if sar_trend == 'up':
                    signals['signals'].append(f'ğŸŸ¢ SAR=${sar:.2f}({sar_distance:.1f}%) æŒç»­çœ‹æ¶¨')
                    signals['score'] += 15
                else:
                    signals['signals'].append(f'ğŸš€ SAR=${sar:.2f}({sar_distance:.1f}%) è½¬å‘çœ‹æ¶¨ - å…³é”®ä¹°å…¥ä¿¡å·')
                    signals['score'] += 20
            elif sar_signal == 'sell':
                if sar_trend == 'down':
                    signals['signals'].append(f'ğŸ”´ SAR=${sar:.2f}({sar_distance:.1f}%) æŒç»­çœ‹è·Œ')
                    signals['score'] -= 15
                else:
                    signals['signals'].append(f'âš ï¸ SAR=${sar:.2f}({sar_distance:.1f}%) è½¬å‘çœ‹è·Œ - å…³é”®å–å‡ºä¿¡å·')
                    signals['score'] -= 20
        
        # 18. SuperTrendä¿¡å·
        if 'supertrend' in indicators:
            st = indicators['supertrend']
            st_dir = indicators.get('supertrend_direction', 'up')
            current_price = indicators.get('current_price', 0)
            
            if st_dir == 'up':
                if current_price > st:
                    signals['signals'].append(f'ğŸŸ¢ SuperTrendæ”¯æ’‘(${st:.2f}) - è¶‹åŠ¿çœ‹æ¶¨')
                    signals['score'] += 20
            else:
                if current_price < st:
                    signals['signals'].append(f'ğŸ”´ SuperTrendé˜»åŠ›(${st:.2f}) - è¶‹åŠ¿çœ‹è·Œ')
                    signals['score'] -= 20
                    
        # 19. StochRSIä¿¡å·
        if 'stoch_rsi_k' in indicators and 'stoch_rsi_d' in indicators:
            k = indicators['stoch_rsi_k']
            d = indicators['stoch_rsi_d']
            status = indicators.get('stoch_rsi_status', 'neutral')
            
            if status == 'oversold':
                if k > d: # é‡‘å‰
                    signals['signals'].append(f'ğŸš€ StochRSIè¶…å–é‡‘å‰(K={k:.1f}) - å¼ºçƒˆåå¼¹ä¿¡å·')
                    signals['score'] += 18
                else:
                    signals['signals'].append(f'ğŸŸ¢ StochRSIè¶…å–(K={k:.1f}) - ç­‰å¾…åå¼¹')
                    signals['score'] += 10
            elif status == 'overbought':
                if k < d: # æ­»å‰
                    signals['signals'].append(f'âš ï¸ StochRSIè¶…ä¹°æ­»å‰(K={k:.1f}) - å›è°ƒé£é™©å¤§')
                    signals['score'] -= 18
                else:
                    signals['signals'].append(f'ğŸ”´ StochRSIè¶…ä¹°(K={k:.1f}) - è­¦æƒ•å›è°ƒ')
                    signals['score'] -= 10
                    
        # 20. Volume Profileä¿¡å·
        if 'vp_poc' in indicators:
            poc = indicators['vp_poc']
            current_price = indicators.get('current_price', 0)
            vp_status = indicators.get('vp_status', 'inside_va')
            
            dist_pct = (current_price - poc) / poc * 100
            
            if abs(dist_pct) < 0.5:
                signals['signals'].append(f'âš–ï¸ ä»·æ ¼åœ¨POC(${poc:.2f})é™„è¿‘ - ç­¹ç å¯†é›†åŒºå¹³è¡¡')
            elif vp_status == 'above_va':
                signals['signals'].append(f'ğŸ“ˆ ä»·æ ¼åœ¨ä»·å€¼åŒºåŸŸä¸Šæ–¹(POC ${poc:.2f}) - å¼ºåŠ¿å¤±è¡¡')
                signals['score'] += 12
            elif vp_status == 'below_va':
                signals['signals'].append(f'ğŸ“‰ ä»·æ ¼åœ¨ä»·å€¼åŒºåŸŸä¸‹æ–¹(POC ${poc:.2f}) - å¼±åŠ¿å¤±è¡¡')
                signals['score'] -= 12
        
        # 21. MLé¢„æµ‹ä¿¡å·
        if 'ml_trend' in indicators:
            ml_trend = indicators['ml_trend']
            ml_confidence = indicators.get('ml_confidence', 0)
            ml_prediction = indicators.get('ml_prediction', 0)
            
            if ml_confidence > 50:
                if ml_trend == 'up':
                    signals['signals'].append(f'ğŸ¤– MLé¢„æµ‹: çœ‹æ¶¨è¶‹åŠ¿(ç½®ä¿¡åº¦{ml_confidence:.1f}%, é¢„æœŸæ¶¨å¹…{ml_prediction*100:.2f}%) - AIçœ‹å¤š')
                    signals['score'] += 15
                elif ml_trend == 'down':
                    signals['signals'].append(f'ğŸ¤– MLé¢„æµ‹: çœ‹è·Œè¶‹åŠ¿(ç½®ä¿¡åº¦{ml_confidence:.1f}%, é¢„æœŸè·Œå¹…{ml_prediction*100:.2f}%) - AIçœ‹ç©º')
                    signals['score'] -= 15
                else:
                    signals['signals'].append(f'ğŸ¤– MLé¢„æµ‹: æ¨ªç›˜æ•´ç†(ç½®ä¿¡åº¦{ml_confidence:.1f}%) - AIä¸­æ€§')
            elif ml_confidence > 30:
                if ml_trend == 'up':
                    signals['signals'].append(f'ğŸ¤– MLé¢„æµ‹: è½»å¾®çœ‹æ¶¨(ç½®ä¿¡åº¦{ml_confidence:.1f}%) - è°¨æ…ä¹è§‚')
                    signals['score'] += 8
                elif ml_trend == 'down':
                    signals['signals'].append(f'ğŸ¤– MLé¢„æµ‹: è½»å¾®çœ‹è·Œ(ç½®ä¿¡åº¦{ml_confidence:.1f}%) - è°¨æ…æ‚²è§‚')
                    signals['score'] -= 8
                
        # ç»¼åˆå»ºè®®
        score = signals['score']
        if score >= 40:
            signals['recommendation'] = 'ğŸŸ¢ å¼ºçƒˆä¹°å…¥'
            signals['action'] = 'strong_buy'
        elif score >= 20:
            signals['recommendation'] = 'ğŸŸ¢ ä¹°å…¥'
            signals['action'] = 'buy'
        elif score >= 0:
            signals['recommendation'] = 'âšª ä¸­æ€§åå¤š'
            signals['action'] = 'hold_bullish'
        elif score >= -20:
            signals['recommendation'] = 'âšª ä¸­æ€§åç©º'
            signals['action'] = 'hold_bearish'
        elif score >= -40:
            signals['recommendation'] = 'ğŸ”´ å–å‡º'
            signals['action'] = 'sell'
        else:
            signals['recommendation'] = 'ğŸ”´ å¼ºçƒˆå–å‡º'
            signals['action'] = 'strong_sell'
        
        # é£é™©è¯„ä¼°
        risk_assessment = _assess_risk(indicators)
        signals['risk'] = {
            'level': risk_assessment['level'],
            'score': risk_assessment['score'],
            'factors': risk_assessment['factors']
        }
        # ä¿ç•™é¡¶çº§å­—æ®µä»¥å…¼å®¹æ—§ä»£ç 
        signals['risk_level'] = risk_assessment['level']
        signals['risk_score'] = risk_assessment['score']
        signals['risk_factors'] = risk_assessment['factors']
        
        # æ­¢æŸæ­¢ç›ˆå»ºè®®
        stop_loss_profit = _calculate_stop_loss_profit(indicators)
        signals['stop_loss'] = stop_loss_profit.get('stop_loss')
        signals['take_profit'] = stop_loss_profit.get('take_profit')
            
        return signals

def _assess_risk(indicators: dict):
        """
        è¯„ä¼°æŠ•èµ„é£é™©ç­‰çº§
        """
        risk_score = 0
        risk_factors = []
        
        # 1. æ³¢åŠ¨ç‡é£é™©
        if 'volatility_20' in indicators:
            vol = indicators['volatility_20']
            if vol > 5:
                risk_score += 30
                risk_factors.append(f'æé«˜æ³¢åŠ¨ç‡({vol:.1f}%)')
            elif vol > 3:
                risk_score += 20
                risk_factors.append(f'é«˜æ³¢åŠ¨ç‡({vol:.1f}%)')
            elif vol > 2:
                risk_score += 10
                risk_factors.append(f'ä¸­ç­‰æ³¢åŠ¨ç‡({vol:.1f}%)')
        
        # 2. RSIæç«¯å€¼
        if 'rsi' in indicators:
            rsi = indicators['rsi']
            if rsi > 85 or rsi < 15:
                risk_score += 20
                risk_factors.append(f'RSIæç«¯å€¼({rsi:.1f})')
        
        # 3. è¿ç»­æ¶¨è·Œé£é™©
        if 'consecutive_up_days' in indicators:
            up_days = indicators['consecutive_up_days']
            if up_days >= 7:
                risk_score += 25
                risk_factors.append(f'è¿ç»­ä¸Šæ¶¨{up_days}å¤©(å›è°ƒé£é™©)')
            elif up_days >= 5:
                risk_score += 15
                risk_factors.append(f'è¿ç»­ä¸Šæ¶¨{up_days}å¤©')
        
        if 'consecutive_down_days' in indicators:
            down_days = indicators['consecutive_down_days']
            if down_days >= 7:
                risk_score += 25
                risk_factors.append(f'è¿ç»­ä¸‹è·Œ{down_days}å¤©(ç»§ç»­ä¸‹è·Œé£é™©)')
            elif down_days >= 5:
                risk_score += 15
                risk_factors.append(f'è¿ç»­ä¸‹è·Œ{down_days}å¤©')
        
        # 4. è·ç¦»æ”¯æ’‘/å‹åŠ›ä½
        current_price = indicators.get('current_price')
        if current_price and 'support_20d_low' in indicators:
            support = indicators['support_20d_low']
            dist_to_support = ((current_price - support) / current_price) * 100
            if dist_to_support < 2:
                risk_score += 15
                risk_factors.append('æ¥è¿‘é‡è¦æ”¯æ’‘ä½')
        
        if current_price and 'resistance_20d_high' in indicators:
            resistance = indicators['resistance_20d_high']
            dist_to_resistance = ((resistance - current_price) / current_price) * 100
            if dist_to_resistance < 2:
                risk_score += 15
                risk_factors.append('æ¥è¿‘é‡è¦å‹åŠ›ä½')
        
        # 5. è¶‹åŠ¿ä¸æ˜ç¡®
        if 'trend_strength' in indicators:
            strength = indicators['trend_strength']
            if strength < 15:
                risk_score += 10
                risk_factors.append('è¶‹åŠ¿ä¸æ˜ç¡®')
        
        # 6. é‡ä»·èƒŒç¦»
        if 'obv_trend' in indicators:
            obv_trend = indicators['obv_trend']
            price_change = indicators.get('price_change_pct', 0)
            
            if (obv_trend == 'up' and price_change < -1) or (obv_trend == 'down' and price_change > 1):
                risk_score += 15
                risk_factors.append('é‡ä»·èƒŒç¦»')
        
        # 7. ADXè¶‹åŠ¿å¼ºåº¦é£é™©
        if 'adx' in indicators:
            adx = indicators['adx']
            # ADXä½äº20è¡¨ç¤ºè¶‹åŠ¿ä¸æ˜ç¡®ï¼Œå¢åŠ äº¤æ˜“é£é™©
            if adx < 20:
                risk_score += 10
                risk_factors.append(f'ADX({adx:.1f})è¶‹åŠ¿ä¸æ˜ç¡®')
            # ADXé«˜äº60è¡¨ç¤ºè¶‹åŠ¿è¿‡å¼ºï¼Œå¯èƒ½åè½¬
            elif adx > 60:
                risk_score += 15
                risk_factors.append(f'ADX({adx:.1f})è¶‹åŠ¿è¿‡å¼ºå¯èƒ½åè½¬')
        
        # åˆ¤æ–­é£é™©ç­‰çº§ï¼ˆè¿”å›è‹±æ–‡æ ‡è¯†ç¬¦ï¼Œå‰ç«¯è´Ÿè´£æ˜¾ç¤ºï¼‰
        if risk_score >= 70:
            level = 'very_high'
        elif risk_score >= 50:
            level = 'high'
        elif risk_score >= 30:
            level = 'medium'
        elif risk_score >= 15:
            level = 'low'
        else:
            level = 'very_low'
        
        return {
            'level': level,
            'score': int(risk_score),
            'factors': risk_factors
        }

def _calculate_stop_loss_profit(indicators: dict):
        """
        è®¡ç®—å»ºè®®çš„æ­¢æŸå’Œæ­¢ç›ˆä»·ä½
        """
        current_price = indicators.get('current_price')
        if not current_price:
            return {}
        
        result = {}
        
        if 'atr' in indicators:
            atr = indicators['atr']
            result['stop_loss'] = float(current_price - 2 * atr)
            result['take_profit'] = float(current_price + 3 * atr)
        elif 'support_20d_low' in indicators and 'resistance_20d_high' in indicators:
            support = indicators['support_20d_low']
            resistance = indicators['resistance_20d_high']
            result['stop_loss'] = float(support * 0.98)
            result['take_profit'] = float(resistance)
        else:
            result['stop_loss'] = float(current_price * 0.95)
            result['take_profit'] = float(current_price * 1.10)
        
        position_sizing = _calculate_position_sizing(indicators, result)
        result.update(position_sizing)
        
        return result

def _calculate_position_sizing(indicators: dict, stop_loss_data: dict):
        """
        è®¡ç®—å»ºè®®çš„ä»“ä½å¤§å°å’Œé£é™©ç®¡ç†
        """
        result = {}
        
        current_price = indicators.get('current_price')
        stop_loss = stop_loss_data.get('stop_loss')
        
        if not current_price or not stop_loss:
            return result
            
        risk_per_share = current_price - stop_loss
        account_value = 100000
        max_risk_amount = account_value * 0.02
        
        if risk_per_share > 0:
            suggested_position_size = int(max_risk_amount / risk_per_share)
            result['suggested_position_size'] = suggested_position_size
            result['position_risk_amount'] = float(suggested_position_size * risk_per_share)
            
            position_value = suggested_position_size * current_price
            result['position_value'] = float(position_value)
            
            position_ratio = (position_value / account_value) * 100
            result['position_ratio'] = float(position_ratio)
            
            risk_level = indicators.get('risk_level', 'medium')
            risk_multiplier = {
                'very_low': 1.5,
                'low': 1.2,
                'medium': 1.0,
                'high': 0.7,
                'very_high': 0.5
            }
            
            adjusted_position_size = int(suggested_position_size * risk_multiplier.get(risk_level, 1.0))
            result['adjusted_position_size'] = adjusted_position_size
            
            result['position_sizing_advice'] = {
                'max_risk_percent': 2,
                'risk_per_share': float(risk_per_share),
                'suggested_size': suggested_position_size,
                'adjusted_size': adjusted_position_size,
                'position_value': float(position_value),
                'account_value': account_value
            }
        
        return result


# ==================== APIæ¥å£ ====================

@app.route('/api/health', methods=['GET'])
def health():
    """
    å¥åº·æ£€æŸ¥æ¥å£
    """
    return jsonify({
        'status': 'ok',
        'gateway': 'yfinance',
        'timestamp': datetime.now().isoformat()
    })


def _check_ollama_available():
    """
    æ£€æŸ¥ Ollama æ˜¯å¦å¯ç”¨
    """
    try:
        import ollama
        import requests
        
        ollama_host = os.getenv('OLLAMA_HOST', 'http://localhost:11434')
        
        try:
            response = requests.get(f'{ollama_host}/api/tags', timeout=2)
            if response.status_code == 200:
                try:
                    client = ollama.Client(host=ollama_host)
                    client.list()
                    return True
                except Exception:
                    return True
            return False
        except Exception:
            return False
    except ImportError:
        return False


def _perform_ai_analysis(symbol, indicators, signals, duration, model='deepseek-v3.1:671b-cloud'):
    """
    æ‰§è¡ŒAIåˆ†æçš„è¾…åŠ©å‡½æ•°
    """
    try:
        import ollama
        
        fundamental_data = indicators.get('fundamental_data', {})
        has_fundamental = (fundamental_data and 
                          isinstance(fundamental_data, dict) and 
                          'raw_xml' not in fundamental_data and
                          len(fundamental_data) > 0)
        
        if has_fundamental:
            fundamental_sections = []
            
            if 'CompanyName' in fundamental_data:
                info_parts = [f"å…¬å¸åç§°: {fundamental_data['CompanyName']}"]
                if 'Exchange' in fundamental_data:
                    info_parts.append(f"äº¤æ˜“æ‰€: {fundamental_data['Exchange']}")
                if 'Employees' in fundamental_data:
                    info_parts.append(f"å‘˜å·¥æ•°: {fundamental_data['Employees']}äºº")
                if 'SharesOutstanding' in fundamental_data:
                    shares = fundamental_data['SharesOutstanding']
                    try:
                        shares_val = float(shares)
                        if shares_val >= 1e9:
                            shares_str = f"{shares_val/1e9:.2f}Bè‚¡"
                        elif shares_val >= 1e6:
                            shares_str = f"{shares_val/1e6:.2f}Mè‚¡"
                        else:
                            shares_str = f"{int(shares_val):,}è‚¡"
                        info_parts.append(f"æµé€šè‚¡æ•°: {shares_str}")
                    except:
                        info_parts.append(f"æµé€šè‚¡æ•°: {shares}")
                if info_parts:
                    fundamental_sections.append("åŸºæœ¬ä¿¡æ¯:\n" + "\n".join([f"   - {p}" for p in info_parts]))
            
            # å¸‚å€¼å’Œä»·æ ¼
            price_parts = []
            if 'MarketCap' in fundamental_data:
                try:
                    mcap = float(fundamental_data['MarketCap'])
                    if mcap >= 1e9:
                        price_parts.append(f"å¸‚å€¼: ${mcap/1e9:.2f}B")
                    elif mcap >= 1e6:
                        price_parts.append(f"å¸‚å€¼: ${mcap/1e6:.2f}M")
                    else:
                        price_parts.append(f"å¸‚å€¼: ${mcap:.2f}")
                except:
                    price_parts.append(f"å¸‚å€¼: {fundamental_data['MarketCap']}")
            if 'Price' in fundamental_data:
                price_parts.append(f"å½“å‰ä»·: ${fundamental_data['Price']}")
            if '52WeekHigh' in fundamental_data and '52WeekLow' in fundamental_data:
                price_parts.append(f"52å‘¨åŒºé—´: ${fundamental_data['52WeekLow']} - ${fundamental_data['52WeekHigh']}")
            if price_parts:
                fundamental_sections.append("å¸‚å€¼ä¸ä»·æ ¼:\n" + "\n".join([f"   - {p}" for p in price_parts]))
            
            # è´¢åŠ¡æŒ‡æ ‡
            financial_parts = []
            for key, label in [('RevenueTTM', 'è¥æ”¶(TTM)'), ('NetIncomeTTM', 'å‡€åˆ©æ¶¦(TTM)'), 
                              ('EBITDATTM', 'EBITDA(TTM)'), ('ProfitMargin', 'åˆ©æ¶¦ç‡'), 
                              ('GrossMargin', 'æ¯›åˆ©ç‡')]:
                if key in fundamental_data:
                    value = fundamental_data[key]
                    try:
                        val = float(value)
                        if 'Margin' in key:
                            financial_parts.append(f"{label}: {val:.2f}%")
                        elif val >= 1e9:
                            financial_parts.append(f"{label}: ${val/1e9:.2f}B")
                        elif val >= 1e6:
                            financial_parts.append(f"{label}: ${val/1e6:.2f}M")
                        else:
                            financial_parts.append(f"{label}: ${val:.2f}")
                    except:
                        financial_parts.append(f"{label}: {value}")
            if financial_parts:
                fundamental_sections.append("è´¢åŠ¡æŒ‡æ ‡:\n" + "\n".join([f"   - {p}" for p in financial_parts]))
            
            # æ¯è‚¡æ•°æ®
            per_share_parts = []
            for key, label in [('EPS', 'æ¯è‚¡æ”¶ç›Š(EPS)'), ('BookValuePerShare', 'æ¯è‚¡å‡€èµ„äº§'), 
                              ('CashPerShare', 'æ¯è‚¡ç°é‡‘'), ('DividendPerShare', 'æ¯è‚¡è‚¡æ¯')]:
                if key in fundamental_data:
                    value = fundamental_data[key]
                    try:
                        val = float(value)
                        per_share_parts.append(f"{label}: ${val:.2f}")
                    except:
                        per_share_parts.append(f"{label}: {value}")
            if per_share_parts:
                fundamental_sections.append("æ¯è‚¡æ•°æ®:\n" + "\n".join([f"   - {p}" for p in per_share_parts]))
            
            # ä¼°å€¼æŒ‡æ ‡
            valuation_parts = []
            for key, label in [('PE', 'å¸‚ç›ˆç‡(PE)'), ('PriceToBook', 'å¸‚å‡€ç‡(PB)'), ('ROE', 'å‡€èµ„äº§æ”¶ç›Šç‡(ROE)')]:
                if key in fundamental_data:
                    value = fundamental_data[key]
                    try:
                        val = float(value)
                        if key == 'ROE':
                            valuation_parts.append(f"{label}: {val:.2f}%")
                        else:
                            valuation_parts.append(f"{label}: {val:.2f}")
                    except:
                        valuation_parts.append(f"{label}: {value}")
            if valuation_parts:
                fundamental_sections.append("ä¼°å€¼æŒ‡æ ‡:\n" + "\n".join([f"   - {p}" for p in valuation_parts]))
            
            # é¢„æµ‹æ•°æ®
            forecast_parts = []
            if 'TargetPrice' in fundamental_data:
                try:
                    target = float(fundamental_data['TargetPrice'])
                    forecast_parts.append(f"ç›®æ ‡ä»·: ${target:.2f}")
                except:
                    forecast_parts.append(f"ç›®æ ‡ä»·: {fundamental_data['TargetPrice']}")
            if 'ConsensusRecommendation' in fundamental_data:
                try:
                    consensus = float(fundamental_data['ConsensusRecommendation'])
                    if consensus <= 1.5:
                        rec = "å¼ºçƒˆä¹°å…¥"
                    elif consensus <= 2.5:
                        rec = "ä¹°å…¥"
                    elif consensus <= 3.5:
                        rec = "æŒæœ‰"
                    elif consensus <= 4.5:
                        rec = "å–å‡º"
                    else:
                        rec = "å¼ºçƒˆå–å‡º"
                    forecast_parts.append(f"å…±è¯†è¯„çº§: {rec} ({consensus:.2f})")
                except:
                    forecast_parts.append(f"å…±è¯†è¯„çº§: {fundamental_data['ConsensusRecommendation']}")
            if 'ProjectedEPS' in fundamental_data:
                try:
                    proj_eps = float(fundamental_data['ProjectedEPS'])
                    forecast_parts.append(f"é¢„æµ‹EPS: ${proj_eps:.2f}")
                except:
                    forecast_parts.append(f"é¢„æµ‹EPS: {fundamental_data['ProjectedEPS']}")
            if 'ProjectedGrowthRate' in fundamental_data:
                try:
                    growth = float(fundamental_data['ProjectedGrowthRate'])
                    forecast_parts.append(f"é¢„æµ‹å¢é•¿ç‡: {growth:.2f}%")
                except:
                    forecast_parts.append(f"é¢„æµ‹å¢é•¿ç‡: {fundamental_data['ProjectedGrowthRate']}")
            if forecast_parts:
                fundamental_sections.append("åˆ†æå¸ˆé¢„æµ‹:\n" + "\n".join([f"   - {p}" for p in forecast_parts]))
            
            # è¯¦ç»†è´¢åŠ¡æŠ¥è¡¨æ•°æ®
            if fundamental_data.get('Financials'):
                try:
                    financials = fundamental_data['Financials']
                    if isinstance(financials, list) and len(financials) > 0:
                        financials_text = "å¹´åº¦è´¢åŠ¡æŠ¥è¡¨:\n"
                        for record in financials[:5]:  # æœ€è¿‘5å¹´
                            if isinstance(record, dict):
                                date = record.get('index', record.get('Date', 'N/A'))
                                financials_text += f"   {date}:\n"
                                for key, value in record.items():
                                    if key not in ['index', 'Date'] and value:
                                        try:
                                            val = float(value)
                                            if abs(val) >= 1e9:
                                                financials_text += f"     - {key}: ${val/1e9:.2f}B\n"
                                            elif abs(val) >= 1e6:
                                                financials_text += f"     - {key}: ${val/1e6:.2f}M\n"
                                            else:
                                                financials_text += f"     - {key}: ${val:.2f}\n"
                                        except:
                                            financials_text += f"     - {key}: {value}\n"
                        fundamental_sections.append(financials_text)
                except Exception as e:
                    logger.warning(f"æ ¼å¼åŒ–å¹´åº¦è´¢åŠ¡æŠ¥è¡¨å¤±è´¥: {e}")
            
            if fundamental_data.get('QuarterlyFinancials'):
                try:
                    quarterly = fundamental_data['QuarterlyFinancials']
                    if isinstance(quarterly, list) and len(quarterly) > 0:
                        quarterly_text = "å­£åº¦è´¢åŠ¡æŠ¥è¡¨:\n"
                        for record in quarterly[:4]:  # æœ€è¿‘4ä¸ªå­£åº¦
                            if isinstance(record, dict):
                                date = record.get('index', record.get('Date', 'N/A'))
                                quarterly_text += f"   {date}:\n"
                                for key, value in record.items():
                                    if key not in ['index', 'Date'] and value:
                                        try:
                                            val = float(value)
                                            if abs(val) >= 1e9:
                                                quarterly_text += f"     - {key}: ${val/1e9:.2f}B\n"
                                            elif abs(val) >= 1e6:
                                                quarterly_text += f"     - {key}: ${val/1e6:.2f}M\n"
                                            else:
                                                quarterly_text += f"     - {key}: ${val:.2f}\n"
                                        except:
                                            quarterly_text += f"     - {key}: {value}\n"
                        fundamental_sections.append(quarterly_text)
                except Exception as e:
                    logger.warning(f"æ ¼å¼åŒ–å­£åº¦è´¢åŠ¡æŠ¥è¡¨å¤±è´¥: {e}")
            
            if fundamental_data.get('BalanceSheet'):
                try:
                    balance = fundamental_data['BalanceSheet']
                    if isinstance(balance, list) and len(balance) > 0:
                        balance_text = "å¹´åº¦èµ„äº§è´Ÿå€ºè¡¨:\n"
                        for record in balance[:3]:  # æœ€è¿‘3å¹´
                            if isinstance(record, dict):
                                date = record.get('index', record.get('Date', 'N/A'))
                                balance_text += f"   {date}:\n"
                                for key, value in record.items():
                                    if key not in ['index', 'Date'] and value:
                                        try:
                                            val = float(value)
                                            if abs(val) >= 1e9:
                                                balance_text += f"     - {key}: ${val/1e9:.2f}B\n"
                                            elif abs(val) >= 1e6:
                                                balance_text += f"     - {key}: ${val/1e6:.2f}M\n"
                                            else:
                                                balance_text += f"     - {key}: ${val:.2f}\n"
                                        except:
                                            balance_text += f"     - {key}: {value}\n"
                        fundamental_sections.append(balance_text)
                except Exception as e:
                    logger.warning(f"æ ¼å¼åŒ–èµ„äº§è´Ÿå€ºè¡¨å¤±è´¥: {e}")
            
            if fundamental_data.get('Cashflow'):
                try:
                    cashflow = fundamental_data['Cashflow']
                    if isinstance(cashflow, list) and len(cashflow) > 0:
                        cashflow_text = "å¹´åº¦ç°é‡‘æµé‡è¡¨:\n"
                        for record in cashflow[:3]:  # æœ€è¿‘3å¹´
                            if isinstance(record, dict):
                                date = record.get('index', record.get('Date', 'N/A'))
                                cashflow_text += f"   {date}:\n"
                                for key, value in record.items():
                                    if key not in ['index', 'Date'] and value:
                                        try:
                                            val = float(value)
                                            if abs(val) >= 1e9:
                                                cashflow_text += f"     - {key}: ${val/1e9:.2f}B\n"
                                            elif abs(val) >= 1e6:
                                                cashflow_text += f"     - {key}: ${val/1e6:.2f}M\n"
                                            else:
                                                cashflow_text += f"     - {key}: ${val:.2f}\n"
                                        except:
                                            cashflow_text += f"     - {key}: {value}\n"
                        fundamental_sections.append(cashflow_text)
                except Exception as e:
                    logger.warning(f"æ ¼å¼åŒ–ç°é‡‘æµé‡è¡¨å¤±è´¥: {e}")
            
            fundamental_text = "\n\n".join(fundamental_sections) if fundamental_sections else "æ— å¯ç”¨æ•°æ®"
        else:
            fundamental_text = None
        
        # æ ¹æ®æ˜¯å¦æœ‰åŸºæœ¬é¢æ•°æ®æ„å»ºä¸åŒçš„æç¤ºè¯
        if has_fundamental:
            # æœ‰åŸºæœ¬é¢æ•°æ®çš„å®Œæ•´åˆ†ææç¤ºè¯
            prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆï¼Œæ“…é•¿ç»“åˆæŠ€æœ¯åˆ†æå’ŒåŸºæœ¬é¢åˆ†æã€‚è¯·åŸºäºä»¥ä¸‹æŠ€æœ¯æŒ‡æ ‡å’ŒåŸºæœ¬é¢æ•°æ®ï¼Œç»™å‡ºå…¨é¢çš„æŠ•èµ„åˆ†æå’Œå»ºè®®ã€‚

è‚¡ç¥¨ä»£ç : {symbol.upper()}
å½“å‰ä»·æ ¼: ${indicators.get('current_price', 0):.2f}
æ•°æ®å‘¨æœŸ: {duration} ({indicators.get('data_points', 0)}ä¸ªæ•°æ®ç‚¹)

ã€æŠ€æœ¯æŒ‡æ ‡åˆ†æã€‘
1. ç§»åŠ¨å¹³å‡çº¿:
   - MA5: ${indicators.get('ma5', 0):.2f}
   - MA20: ${indicators.get('ma20', 0):.2f}
   - MA50: ${indicators.get('ma50', 0):.2f}

2. åŠ¨é‡æŒ‡æ ‡:
   - RSI(14): {indicators.get('rsi', 0):.1f}
   - MACD: {indicators.get('macd', 0):.3f}
   - ä¿¡å·çº¿: {indicators.get('macd_signal', 0):.3f}

3. æ³¢åŠ¨æŒ‡æ ‡:
   - å¸ƒæ—å¸¦ä¸Šè½¨: ${indicators.get('bb_upper', 0):.2f}
   - å¸ƒæ—å¸¦ä¸­è½¨: ${indicators.get('bb_middle', 0):.2f}
   - å¸ƒæ—å¸¦ä¸‹è½¨: ${indicators.get('bb_lower', 0):.2f}
   - ATR: ${indicators.get('atr', 0):.2f}

4. KDJæŒ‡æ ‡:
   - K: {indicators.get('kdj_k', 0):.1f}
   - D: {indicators.get('kdj_d', 0):.1f}
   - J: {indicators.get('kdj_j', 0):.1f}

5. è¶‹åŠ¿åˆ†æ:
   - è¶‹åŠ¿æ–¹å‘: {indicators.get('trend_direction', 'neutral')}
   - è¶‹åŠ¿å¼ºåº¦: {indicators.get('trend_strength', 0):.0f}%
   - è¿ç»­ä¸Šæ¶¨å¤©æ•°: {indicators.get('consecutive_up_days', 0)}
   - è¿ç»­ä¸‹è·Œå¤©æ•°: {indicators.get('consecutive_down_days', 0)}

6. æ”¯æ’‘å‹åŠ›ä½:
   - æ¢è½´ç‚¹: ${indicators.get('pivot', 0):.2f}
   - å‹åŠ›ä½R1: ${indicators.get('pivot_r1', 0):.2f}
   - æ”¯æ’‘ä½S1: ${indicators.get('pivot_s1', 0):.2f}

7. ç°ä»£æŠ€æœ¯æŒ‡æ ‡:
   - CCI(é¡ºåŠ¿æŒ‡æ ‡): {indicators.get('cci', 0):.1f}
   - ADX(è¶‹åŠ¿å¼ºåº¦):
     * ADX: {indicators.get('adx', 0):.1f}
     * +DI: {indicators.get('plus_di', 0):.1f}
     * -DI: {indicators.get('minus_di', 0):.1f}
   - VWAP: ${indicators.get('vwap', 0):.2f}
   - SAR(æŠ›ç‰©çº¿): ${indicators.get('sar', 0):.2f}
   - æ–æ³¢é‚£å¥‘å›æ’¤ä½:
     * 23.6%: ${indicators.get('fib_23.6', 0):.2f}
     * 38.2%: ${indicators.get('fib_38.2', 0):.2f}
     * 50.0%: ${indicators.get('fib_50.0', 0):.2f}
     * 61.8%: ${indicators.get('fib_61.8', 0):.2f}
     * 78.6%: ${indicators.get('fib_78.6', 0):.2f}
   - ä¸€ç›®å‡è¡¡è¡¨ (Ichimoku Cloud):
     * è½¬æŠ˜çº¿ (Tenkan): ${indicators.get('ichimoku_tenkan_sen', 0):.2f}
     * åŸºå‡†çº¿ (Kijun): ${indicators.get('ichimoku_kijun_sen', 0):.2f}
     * äº‘å±‚ä¸Šæ²¿: ${indicators.get('ichimoku_cloud_top', 0):.2f}
     * äº‘å±‚ä¸‹æ²¿: ${indicators.get('ichimoku_cloud_bottom', 0):.2f}
     * çŠ¶æ€: {indicators.get('ichimoku_status', 'unknown')}
     * äº¤å‰ä¿¡å·: {indicators.get('ichimoku_tk_cross', 'neutral')}
   - SuperTrend:
     * ä»·æ ¼: ${indicators.get('supertrend', 0):.2f}
     * æ–¹å‘: {indicators.get('supertrend_direction', 'neutral')}
   - StochRSI:
     * K: {indicators.get('stoch_rsi_k', 0):.1f}
     * D: {indicators.get('stoch_rsi_d', 0):.1f}
     * çŠ¶æ€: {indicators.get('stoch_rsi_status', 'neutral')}
   - ç­¹ç åˆ†å¸ƒ (Volume Profile):
     * POC (æ§åˆ¶ç‚¹): ${indicators.get('vp_poc', 0):.2f}
     * ä»·å€¼åŒºä¸Šæ²¿ (VAH): ${indicators.get('vp_vah', 0):.2f}
     * ä»·å€¼åŒºä¸‹æ²¿ (VAL): ${indicators.get('vp_val', 0):.2f}
     * çŠ¶æ€: {indicators.get('vp_status', 'neutral')}

8. æˆäº¤é‡åˆ†æï¼ˆé‡è¦ï¼‰:
   - æˆäº¤é‡æ¯”ç‡: {indicators.get('volume_ratio', 0):.2f} (å½“å‰æˆäº¤é‡/20æ—¥å‡é‡)
   - å½“å‰æˆäº¤é‡: {indicators.get('current_volume', 0):,.0f}
   - 20æ—¥å¹³å‡æˆäº¤é‡: {indicators.get('avg_volume_20', 0):,.0f}
   - OBVèƒ½é‡æ½®: {indicators.get('obv_current', 0):,.0f}
   - OBVè¶‹åŠ¿: {indicators.get('obv_trend', 'neutral')}
   - VWAPæˆäº¤é‡åŠ æƒå¹³å‡ä»·: ${indicators.get('vwap', 0):.2f}
   - VWAPåç¦»åº¦: {indicators.get('vwap_deviation', 0):.2f}%
   - VWAPä¿¡å·: {indicators.get('vwap_signal', 'neutral')}
   - MLé¢„æµ‹ä»·é‡å…³ç³»:
     * ä»·é‡é…åˆ: {indicators.get('price_volume_confirmation', 'neutral')}
     * æˆäº¤é‡ä¿¡å·: {indicators.get('volume_signal', 'normal')}
     * æˆäº¤é‡æ¯”ç‡: {indicators.get('volume_ratio', 1.0):.2f}
     * ä»·é‡èƒŒç¦»åº¦: {indicators.get('price_volume_divergence', 0):.3f}

9. MLé¢„æµ‹ï¼ˆæœºå™¨å­¦ä¹ ï¼‰:
   - é¢„æµ‹è¶‹åŠ¿: {indicators.get('ml_trend', 'unknown')}
   - é¢„æµ‹ç½®ä¿¡åº¦: {indicators.get('ml_confidence', 0):.1f}%
   - é¢„æœŸä»·æ ¼å˜åŒ–: {indicators.get('ml_prediction', 0)*100:.2f}%

10. é£é™©è¯„ä¼°:
   - é£é™©ç­‰çº§: {signals.get('risk', {}).get('level', 'unknown') if signals.get('risk') else 'unknown'}
   - é£é™©è¯„åˆ†: {signals.get('risk', {}).get('score', 0) if signals.get('risk') else 0}/100

11. ç³»ç»Ÿå»ºè®®:
   - ç»¼åˆè¯„åˆ†: {signals.get('score', 0)}/100
   - å»ºè®®æ“ä½œ: {signals.get('recommendation', 'unknown')}

ã€åŸºæœ¬é¢åˆ†æã€‘
{fundamental_text}

è¯·æä¾›ä»¥ä¸‹åˆ†æ:
1. æŠ€æœ¯é¢åˆ†æ: å½“å‰å¸‚åœºçŠ¶æ€ï¼ˆè¶‹åŠ¿ã€åŠ¨èƒ½ã€æ³¢åŠ¨ï¼‰ã€å…³é”®æŠ€æœ¯ä¿¡å·è§£è¯»
2. æˆäº¤é‡åˆ†æï¼ˆé‡è¦ï¼‰:
   - åˆ†æå½“å‰æˆäº¤é‡æ°´å¹³ï¼ˆä¸å†å²å¹³å‡æˆäº¤é‡å¯¹æ¯”ï¼‰
   - ä»·é‡å…³ç³»åˆ†æï¼šä»·æ ¼ä¸Šæ¶¨/ä¸‹è·Œæ—¶æˆäº¤é‡çš„é…åˆæƒ…å†µ
   - ä»·é‡èƒŒç¦»æ£€æµ‹ï¼šæ˜¯å¦å­˜åœ¨ä»·æ¶¨é‡ç¼©æˆ–ä»·è·Œé‡å¢çš„èƒŒç¦»ç°è±¡
   - OBVèƒ½é‡æ½®è¶‹åŠ¿åˆ†æï¼šèµ„é‡‘æµå‘åˆ¤æ–­
   - VWAPä½ç½®åˆ†æï¼šå½“å‰ä»·æ ¼ç›¸å¯¹äºæœºæ„æˆæœ¬çº¿çš„ä½ç½®
   - Volume Profileåˆ†æï¼šç­¹ç åˆ†å¸ƒæƒ…å†µï¼ŒPOCå’Œä»·å€¼åŒºåŸŸçš„æ„ä¹‰
   - MLé¢„æµ‹çš„ä»·é‡å…³ç³»ï¼šæœºå™¨å­¦ä¹ æ¨¡å‹å¯¹ä»·é‡é…åˆçš„åˆ¤æ–­
   - æˆäº¤é‡å¯¹è¶‹åŠ¿çš„ç¡®è®¤æˆ–å¦å®šä½œç”¨
3. åŸºæœ¬é¢åˆ†æ: 
   - åŸºäºè´¢åŠ¡æŒ‡æ ‡å’Œè´¢åŠ¡æŠ¥è¡¨æ•°æ®ï¼Œåˆ†æå…¬å¸è´¢åŠ¡çŠ¶å†µã€ç›ˆåˆ©èƒ½åŠ›ã€ç°é‡‘æµå¥åº·åº¦
   - é€šè¿‡å¯¹æ¯”å¹´åº¦å’Œå­£åº¦è´¢åŠ¡æŠ¥è¡¨ï¼Œè¯†åˆ«è¥æ”¶ã€åˆ©æ¶¦ã€ç°é‡‘æµçš„å˜åŒ–è¶‹åŠ¿
   - åˆ†æèµ„äº§è´Ÿå€ºè¡¨ï¼Œè¯„ä¼°å…¬å¸èµ„äº§ç»“æ„ã€è´Ÿå€ºæ°´å¹³å’Œè´¢åŠ¡ç¨³å¥æ€§
   - ç»“åˆæœºæ„æŒæœ‰äººä¿¡æ¯ï¼Œè¯„ä¼°å¸‚åœºå¯¹å…¬å¸å‰æ™¯çš„è®¤å¯åº¦
   - ä¼°å€¼æ°´å¹³åˆ†æï¼šç»“åˆPEã€PBã€ROEç­‰æŒ‡æ ‡ï¼Œåˆ¤æ–­å½“å‰ä¼°å€¼æ˜¯å¦åˆç†
3. ç»¼åˆåˆ†æ: ç»“åˆæŠ€æœ¯é¢å’ŒåŸºæœ¬é¢ï¼Œç»™å‡ºä¹°å…¥/å–å‡º/è§‚æœ›çš„å…·ä½“å»ºè®®
4. é£é™©æç¤º: æŠ€æœ¯é£é™©å’ŒåŸºæœ¬é¢é£é™©çš„ç»¼åˆè¯„ä¼°ï¼ˆé‡ç‚¹å…³æ³¨è´¢åŠ¡æŠ¥è¡¨ä¸­çš„é£é™©ä¿¡å·ï¼‰
5. æ“ä½œå»ºè®®: å»ºè®®çš„æ­¢æŸæ­¢ç›ˆä½ã€ä»“ä½ç®¡ç†å»ºè®®ï¼ˆé‡ç‚¹å…³æ³¨SARæ­¢æŸä½å’ŒVWAPä»·æ ¼åç¦»åº¦ï¼‰
6. å¸‚åœºå±•æœ›: ç»“åˆæŠ€æœ¯æŒ‡æ ‡å’ŒåŸºæœ¬é¢æ•°æ®ï¼Œåˆ†ææœªæ¥å¯èƒ½çš„æƒ…å¢ƒï¼ˆç‰›å¸‚ã€ç†Šå¸‚ã€éœ‡è¡å¸‚ä¸­çš„ä¸åŒç­–ç•¥ï¼‰

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œç®€æ´ä¸“ä¸šï¼Œé‡ç‚¹çªå‡ºï¼Œå°†æŠ€æœ¯åˆ†æå’ŒåŸºæœ¬é¢åˆ†ææœ‰æœºç»“åˆã€‚åœ¨åŸºæœ¬é¢åˆ†æä¸­ï¼Œè¯·å……åˆ†åˆ©ç”¨æä¾›çš„è´¢åŠ¡æŠ¥è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨ç­‰è¯¦ç»†æ•°æ®ï¼Œè¿›è¡Œæ·±å…¥åˆ†æã€‚"""
        else:
            # æ²¡æœ‰åŸºæœ¬é¢æ•°æ®ï¼Œåªè¿›è¡ŒæŠ€æœ¯åˆ†æ
            prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨æŠ€æœ¯åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼Œç»™å‡ºè¯¦ç»†çš„æŠ€æœ¯åˆ†æå’Œäº¤æ˜“å»ºè®®ã€‚

è‚¡ç¥¨ä»£ç : {symbol.upper()}
å½“å‰ä»·æ ¼: ${indicators.get('current_price', 0):.2f}
æ•°æ®å‘¨æœŸ: {duration} ({indicators.get('data_points', 0)}ä¸ªæ•°æ®ç‚¹)

ã€æ³¨æ„ã€‘è¯¥è‚¡ç¥¨æš‚æ— åŸºæœ¬é¢æ•°æ®ï¼ˆå¯èƒ½æ˜¯ETFæˆ–ç‰¹æ®Šè¯åˆ¸ï¼‰ï¼Œè¯·ä»…åŸºäºæŠ€æœ¯æŒ‡æ ‡è¿›è¡Œåˆ†æã€‚

æŠ€æœ¯æŒ‡æ ‡:
1. ç§»åŠ¨å¹³å‡çº¿:
   - MA5: ${indicators.get('ma5', 0):.2f}
   - MA20: ${indicators.get('ma20', 0):.2f}
   - MA50: ${indicators.get('ma50', 0):.2f}

2. åŠ¨é‡æŒ‡æ ‡:
   - RSI(14): {indicators.get('rsi', 0):.1f}
   - MACD: {indicators.get('macd', 0):.3f}
   - ä¿¡å·çº¿: {indicators.get('macd_signal', 0):.3f}

3. æ³¢åŠ¨æŒ‡æ ‡:
   - å¸ƒæ—å¸¦ä¸Šè½¨: ${indicators.get('bb_upper', 0):.2f}
   - å¸ƒæ—å¸¦ä¸­è½¨: ${indicators.get('bb_middle', 0):.2f}
   - å¸ƒæ—å¸¦ä¸‹è½¨: ${indicators.get('bb_lower', 0):.2f}
   - ATR: ${indicators.get('atr', 0):.2f}

4. KDJæŒ‡æ ‡:
   - K: {indicators.get('kdj_k', 0):.1f}
   - D: {indicators.get('kdj_d', 0):.1f}
   - J: {indicators.get('kdj_j', 0):.1f}

5. è¶‹åŠ¿åˆ†æ:
   - è¶‹åŠ¿æ–¹å‘: {indicators.get('trend_direction', 'neutral')}
   - è¶‹åŠ¿å¼ºåº¦: {indicators.get('trend_strength', 0):.0f}%
   - è¿ç»­ä¸Šæ¶¨å¤©æ•°: {indicators.get('consecutive_up_days', 0)}
   - è¿ç»­ä¸‹è·Œå¤©æ•°: {indicators.get('consecutive_down_days', 0)}

6. æ”¯æ’‘å‹åŠ›ä½:
   - æ¢è½´ç‚¹: ${indicators.get('pivot', 0):.2f}
   - å‹åŠ›ä½R1: ${indicators.get('pivot_r1', 0):.2f}
   - æ”¯æ’‘ä½S1: ${indicators.get('pivot_s1', 0):.2f}

7. ç°ä»£æŠ€æœ¯æŒ‡æ ‡:
   - CCI(é¡ºåŠ¿æŒ‡æ ‡): {indicators.get('cci', 0):.1f}
   - ADX(è¶‹åŠ¿å¼ºåº¦):
     * ADX: {indicators.get('adx', 0):.1f}
     * +DI: {indicators.get('plus_di', 0):.1f}
     * -DI: {indicators.get('minus_di', 0):.1f}
   - VWAP: ${indicators.get('vwap', 0):.2f}
   - SAR(æŠ›ç‰©çº¿): ${indicators.get('sar', 0):.2f}
   - æ–æ³¢é‚£å¥‘å›æ’¤ä½:
     * 23.6%: ${indicators.get('fib_23.6', 0):.2f}
     * 38.2%: ${indicators.get('fib_38.2', 0):.2f}
     * 50.0%: ${indicators.get('fib_50.0', 0):.2f}
     * 61.8%: ${indicators.get('fib_61.8', 0):.2f}
     * 78.6%: ${indicators.get('fib_78.6', 0):.2f}
   - ä¸€ç›®å‡è¡¡è¡¨ (Ichimoku Cloud):
     * è½¬æŠ˜çº¿ (Tenkan): ${indicators.get('ichimoku_tenkan_sen', 0):.2f}
     * åŸºå‡†çº¿ (Kijun): ${indicators.get('ichimoku_kijun_sen', 0):.2f}
     * äº‘å±‚ä¸Šæ²¿: ${indicators.get('ichimoku_cloud_top', 0):.2f}
     * äº‘å±‚ä¸‹æ²¿: ${indicators.get('ichimoku_cloud_bottom', 0):.2f}
     * çŠ¶æ€: {indicators.get('ichimoku_status', 'unknown')}
     * äº¤å‰ä¿¡å·: {indicators.get('ichimoku_tk_cross', 'neutral')}

8. é£é™©è¯„ä¼°:
   - é£é™©ç­‰çº§: {signals.get('risk', {}).get('level', 'unknown') if signals.get('risk') else 'unknown'}
   - é£é™©è¯„åˆ†: {signals.get('risk', {}).get('score', 0) if signals.get('risk') else 0}/100

9. ç³»ç»Ÿå»ºè®®:
   - ç»¼åˆè¯„åˆ†: {signals.get('score', 0)}/100
   - å»ºè®®æ“ä½œ: {signals.get('recommendation', 'unknown')}

è¯·æä¾›:
1. å½“å‰å¸‚åœºçŠ¶æ€åˆ†æï¼ˆè¶‹åŠ¿ã€åŠ¨èƒ½ã€æ³¢åŠ¨ï¼‰
2. å…³é”®æŠ€æœ¯ä¿¡å·è§£è¯»ï¼ˆåŒ…æ‹¬CCIã€ADXã€VWAPã€SARç­‰ç°ä»£æŠ€æœ¯æŒ‡æ ‡ï¼‰
3. ä¹°å…¥/å–å‡º/è§‚æœ›çš„å…·ä½“å»ºè®®ï¼ˆåŸºäºçº¯æŠ€æœ¯åˆ†æï¼‰
4. é£é™©æç¤ºå’Œæ³¨æ„äº‹é¡¹ï¼ˆé‡ç‚¹å…³æ³¨ADXè¶‹åŠ¿å¼ºåº¦å’ŒCCIè¶…ä¹°è¶…å–ï¼‰
5. å»ºè®®çš„æ­¢æŸæ­¢ç›ˆä½ï¼ˆå‚è€ƒSARæŠ›ç‰©çº¿å’ŒVWAPæ”¯æ’‘å‹åŠ›ï¼‰
6. å¸‚åœºæƒ…ç»ªå’Œå¯èƒ½çš„æƒ…å¢ƒåˆ†æï¼ˆå¦‚ç‰›å¸‚ã€ç†Šå¸‚ã€éœ‡è¡å¸‚ä¸­çš„ä¸åŒç­–ç•¥ï¼‰

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œç®€æ´ä¸“ä¸šï¼Œé‡ç‚¹çªå‡ºã€‚"""

        # è°ƒç”¨Ollamaï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„æœåŠ¡åœ°å€ï¼‰
        ollama_host = os.getenv('OLLAMA_HOST', 'http://localhost:11434')
        try:
            client = ollama.Client(host=ollama_host)
        except Exception:
            client = None
        response = (client.chat if client else ollama.chat)(
            model=model,
            messages=[{
                'role': 'user',
                'content': prompt
            }]
        )
        
        return response['message']['content']
        
    except Exception as ai_error:
        logger.error(f"AIåˆ†æå¤±è´¥: {ai_error}")
        return f'AIåˆ†æä¸å¯ç”¨: {str(ai_error)}\n\nè¯·ç¡®ä¿Ollamaå·²å®‰è£…å¹¶è¿è¡Œ: ollama serve'


@app.route('/api/analyze/<symbol>', methods=['GET'])
def analyze_stock(symbol):
    """
    æŠ€æœ¯åˆ†æ - è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¹¶ç”Ÿæˆä¹°å–ä¿¡å·
    è‡ªåŠ¨æ£€æµ‹ Ollama æ˜¯å¦å¯ç”¨ï¼Œå¦‚æœå¯ç”¨åˆ™è‡ªåŠ¨æ‰§è¡ŒAIåˆ†æ
    ä½¿ç”¨SQLiteç¼“å­˜å½“å¤©çš„æŸ¥è¯¢ç»“æœï¼Œé¿å…é‡å¤æŸ¥è¯¢
    
    æŸ¥è¯¢å‚æ•°:
    - duration: æ•°æ®å‘¨æœŸ (é»˜è®¤: '3 M')
    - bar_size: Kçº¿å‘¨æœŸ (é»˜è®¤: '1 day')
    - model: AIæ¨¡å‹åç§° (é»˜è®¤: 'deepseek-v3.1:671b-cloud')ï¼Œä»…åœ¨Ollamaå¯ç”¨æ—¶ä½¿ç”¨
    """
    duration = request.args.get('duration', '3 M')
    bar_size = request.args.get('bar_size', '1 day')
    model = request.args.get('model', 'deepseek-v3.1:671b-cloud')
    
    symbol_upper = symbol.upper()
    
    # å…ˆæ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦æœ‰å½“å¤©çš„æ•°æ®
    cached_result = get_cached_analysis(symbol_upper, duration, bar_size)
    if cached_result:
        # å¦‚æœç¼“å­˜ä¸­æœ‰AIåˆ†æç»“æœï¼Œç›´æ¥è¿”å›
        if cached_result.get('ai_analysis'):
            return jsonify(cached_result)
        # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰AIåˆ†æï¼Œä½†Ollamaå¯ç”¨ï¼Œåˆ™æ‰§è¡ŒAIåˆ†æå¹¶æ›´æ–°ç¼“å­˜
        if _check_ollama_available():
            logger.info(f"ç¼“å­˜ä¸­æœ‰æ•°æ®ä½†æ— AIåˆ†æï¼Œæ‰§è¡ŒAIåˆ†æ...")
            try:
                ai_analysis = _perform_ai_analysis(
                    symbol_upper, 
                    cached_result['indicators'], 
                    cached_result['signals'], 
                    duration, 
                    model
                )
                cached_result['ai_analysis'] = ai_analysis
                cached_result['model'] = model
                cached_result['ai_available'] = True
                # æ›´æ–°ç¼“å­˜
                save_analysis_cache(symbol_upper, duration, bar_size, cached_result)
            except Exception as e:
                logger.warning(f"AIåˆ†ææ‰§è¡Œå¤±è´¥: {e}")
                cached_result['ai_available'] = False
                cached_result['ai_error'] = str(e)
        return jsonify(cached_result)
    
    logger.info(f"æŠ€æœ¯åˆ†æ: {symbol_upper}, {duration}, {bar_size}")
    
    try:
        stock_info = get_stock_info(symbol_upper)
        if stock_info:
            stock_name = None
            if isinstance(stock_info, dict):
                stock_name = stock_info.get('longName', '')
            elif isinstance(stock_info, list) and len(stock_info) > 0:
                stock_data = stock_info[0]
                if isinstance(stock_data, dict):
                    stock_name = stock_data.get('longName', '')
            
            if stock_name and stock_name.strip() and stock_name != symbol_upper:
                save_stock_info(symbol_upper, stock_name.strip())
    except Exception as e:
        logger.warning(f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
    
    hist_data, hist_error = get_historical_data(symbol_upper, duration, bar_size)
    indicators, ind_error = calculate_technical_indicators(symbol_upper, duration, bar_size)
    
    if ind_error:
        return jsonify({
            'success': False,
            'error_code': ind_error['code'],
            'message': ind_error['message']
        }), 400
    
    if not indicators:
        return jsonify({
            'success': False,
            'message': 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŠ€æœ¯æŒ‡æ ‡'
        }), 404
    
    # ç”Ÿæˆä¹°å–ä¿¡å·
    signals = generate_signals(indicators)
    
    # æ ¼å¼åŒ–Kçº¿æ•°æ®
    formatted_candles = []
    if hist_data:
        for bar in hist_data:
            date_str = bar.get('date', '')
            try:
                if len(date_str) == 8:
                    dt = datetime.strptime(date_str, '%Y%m%d')
                    time_str = dt.strftime('%Y-%m-%d')
                elif ' ' in date_str:
                    dt = datetime.strptime(date_str, '%Y%m%d %H:%M:%S')
                    time_str = dt.strftime('%Y-%m-%d %H:%M:%S')
                else:
                    time_str = date_str
            except Exception as e:
                logger.warning(f"æ—¥æœŸè§£æå¤±è´¥: {date_str}, é”™è¯¯: {e}")
                time_str = date_str
            
            formatted_candles.append({
                'time': time_str,
                'open': float(bar.get('open', 0)),
                'high': float(bar.get('high', 0)),
                'low': float(bar.get('low', 0)),
                'close': float(bar.get('close', 0)),
                'volume': int(bar.get('volume', 0)),
            })
    
    result = {
        'success': True,
        'indicators': indicators,
        'signals': signals,
        'candles': formatted_candles
    }
    
    if _check_ollama_available():
        logger.info(f"æ£€æµ‹åˆ° Ollama å¯ç”¨ï¼Œå¼€å§‹AIåˆ†æ...")
        try:
            ai_analysis = _perform_ai_analysis(symbol_upper, indicators, signals, duration, model)
            result['ai_analysis'] = ai_analysis
            result['model'] = model
            result['ai_available'] = True
        except Exception as e:
            logger.warning(f"AIåˆ†ææ‰§è¡Œå¤±è´¥: {e}")
            result['ai_available'] = False
            result['ai_error'] = str(e)
    else:
        logger.info("Ollama ä¸å¯ç”¨ï¼Œè·³è¿‡AIåˆ†æ")
        result['ai_available'] = False
    
    # ä¿å­˜åˆ°ç¼“å­˜
    save_analysis_cache(symbol_upper, duration, bar_size, result)
    
    return jsonify(result)


@app.route('/api/refresh-analyze/<symbol>', methods=['POST'])
def refresh_analyze_stock(symbol):
    """
    åˆ·æ–°æŠ€æœ¯åˆ†æ - å¼ºåˆ¶é‡æ–°è·å–æ•°æ®å¹¶åˆ†æï¼Œä¸ä½¿ç”¨ç¼“å­˜
    è‡ªåŠ¨æ£€æµ‹ Ollama æ˜¯å¦å¯ç”¨ï¼Œå¦‚æœå¯ç”¨åˆ™è‡ªåŠ¨æ‰§è¡ŒAIåˆ†æ
    
    æŸ¥è¯¢å‚æ•°:
    - duration: æ•°æ®å‘¨æœŸ (é»˜è®¤: '3 M')
    - bar_size: Kçº¿å‘¨æœŸ (é»˜è®¤: '1 day')
    - model: AIæ¨¡å‹åç§° (é»˜è®¤: 'deepseek-v3.1:671b-cloud')ï¼Œä»…åœ¨Ollamaå¯ç”¨æ—¶ä½¿ç”¨
    """
    duration = request.args.get('duration', '3 M')
    bar_size = request.args.get('bar_size', '1 day')
    model = request.args.get('model', 'deepseek-v3.1:671b-cloud')
    
    symbol_upper = symbol.upper()
    
    logger.info(f"åˆ·æ–°æŠ€æœ¯åˆ†æï¼ˆå¼ºåˆ¶é‡æ–°è·å–ï¼‰: {symbol_upper}, {duration}, {bar_size}")
    
    # è·å–è‚¡ç¥¨ä¿¡æ¯å¹¶ä¿å­˜åˆ°æ•°æ®åº“
    try:
        stock_info = get_stock_info(symbol_upper)
        if stock_info:
            stock_name = None
            # å¤„ç†è¿”å›çš„æ•°æ®ç»“æ„
            if isinstance(stock_info, dict):
                stock_name = stock_info.get('longName', '')
            elif isinstance(stock_info, list) and len(stock_info) > 0:
                # å¦‚æœè¿”å›çš„æ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ª
                stock_data = stock_info[0]
                if isinstance(stock_data, dict):
                    stock_name = stock_data.get('longName', '')
            
            # å¦‚æœæœ‰æœ‰æ•ˆçš„è‚¡ç¥¨åç§°ï¼Œä¿å­˜åˆ°æ•°æ®åº“
            if stock_name and stock_name.strip() and stock_name != symbol_upper:
                save_stock_info(symbol_upper, stock_name.strip())
    except Exception as e:
        logger.warning(f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
    
    # è·å–å†å²Kçº¿æ•°æ®
    hist_data, hist_error = get_historical_data(symbol_upper, duration, bar_size)
    
    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    indicators, ind_error = calculate_technical_indicators(symbol_upper, duration, bar_size)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ï¼ˆå¦‚è¯åˆ¸ä¸å­˜åœ¨ï¼‰
    if ind_error:
        return jsonify({
            'success': False,
            'error_code': ind_error['code'],
            'message': ind_error['message']
        }), 400
    
    if not indicators:
        return jsonify({
            'success': False,
            'message': 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŠ€æœ¯æŒ‡æ ‡'
        }), 404
    
    # ç”Ÿæˆä¹°å–ä¿¡å·
    signals = generate_signals(indicators)
    
    # æ ¼å¼åŒ–Kçº¿æ•°æ®
    formatted_candles = []
    if hist_data:
        for bar in hist_data:
            date_str = bar.get('date', '')
            try:
                if len(date_str) == 8:
                    dt = datetime.strptime(date_str, '%Y%m%d')
                    time_str = dt.strftime('%Y-%m-%d')
                elif ' ' in date_str:
                    dt = datetime.strptime(date_str, '%Y%m%d %H:%M:%S')
                    time_str = dt.strftime('%Y-%m-%d %H:%M:%S')
                else:
                    time_str = date_str
            except Exception as e:
                logger.warning(f"æ—¥æœŸè§£æå¤±è´¥: {date_str}, é”™è¯¯: {e}")
                time_str = date_str
            
            formatted_candles.append({
                'time': time_str,
                'open': float(bar.get('open', 0)),
                'high': float(bar.get('high', 0)),
                'low': float(bar.get('low', 0)),
                'close': float(bar.get('close', 0)),
                'volume': int(bar.get('volume', 0)),
            })
    
    result = {
        'success': True,
        'indicators': indicators,
        'signals': signals,
        'candles': formatted_candles
    }
    
    if _check_ollama_available():
        logger.info(f"æ£€æµ‹åˆ° Ollama å¯ç”¨ï¼Œå¼€å§‹AIåˆ†æ...")
        try:
            ai_analysis = _perform_ai_analysis(symbol_upper, indicators, signals, duration, model)
            result['ai_analysis'] = ai_analysis
            result['model'] = model
            result['ai_available'] = True
        except Exception as e:
            logger.warning(f"AIåˆ†ææ‰§è¡Œå¤±è´¥: {e}")
            result['ai_available'] = False
            result['ai_error'] = str(e)
    else:
        logger.info("Ollama ä¸å¯ç”¨ï¼Œè·³è¿‡AIåˆ†æ")
        result['ai_available'] = False
    
    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆæ›´æ–°ç¼“å­˜ï¼‰
    save_analysis_cache(symbol_upper, duration, bar_size, result)
    
    return jsonify(result)


@app.route('/api/hot-stocks', methods=['GET'])
def get_hot_stocks():
    """
    è·å–çƒ­é—¨è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆä»SQLiteæ•°æ®åº“æŸ¥è¯¢è¿‡çš„è‚¡ç¥¨ä¸­è·å–ï¼‰
    æŸ¥è¯¢å‚æ•°:
    - limit: è¿”å›æ•°é‡é™åˆ¶ (é»˜è®¤: 20)
    """
    limit = int(request.args.get('limit', 20))
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # ä»æ•°æ®åº“æŸ¥è¯¢æ‰€æœ‰ä¸åŒçš„è‚¡ç¥¨ä»£ç ï¼ŒæŒ‰æŸ¥è¯¢æ¬¡æ•°å’Œæœ€è¿‘æŸ¥è¯¢æ—¶é—´æ’åº
        # åŒæ—¶å…³è”stock_infoè¡¨è·å–è‚¡ç¥¨å…¨å
        cursor.execute('''
            SELECT 
                ac.symbol,
                COUNT(*) as query_count,
                MAX(ac.created_at) as last_query_time,
                si.name
            FROM analysis_cache ac
            LEFT JOIN stock_info si ON ac.symbol = si.symbol
            GROUP BY ac.symbol
            ORDER BY query_count DESC, last_query_time DESC
            LIMIT ?
        ''', (limit,))
        
        rows = cursor.fetchall()
        conn.close()
        
        # æ„å»ºè¿”å›ç»“æœ
        hot_stocks = []
        for row in rows:
            symbol = row[0]
            stock_name = row[3] if row[3] else symbol  # å¦‚æœæœ‰åç§°å°±ç”¨åç§°ï¼Œå¦åˆ™ç”¨ä»£ç 
            hot_stocks.append({
                'symbol': symbol,
                'name': stock_name,
                'category': 'å·²æŸ¥è¯¢'
            })
        
        # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œè¿”å›ç©ºåˆ—è¡¨
        return jsonify({
            'success': True,
            'market': 'US',
            'count': len(hot_stocks),
            'stocks': hot_stocks
        })
    except Exception as e:
        logger.error(f"æŸ¥è¯¢çƒ­é—¨è‚¡ç¥¨å¤±è´¥: {e}")
        # å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
        return jsonify({
            'success': True,
            'market': 'US',
            'count': 0,
            'stocks': []
        })


def _load_indicator_info():
    """
    ä»JSONæ–‡ä»¶åŠ è½½æŠ€æœ¯æŒ‡æ ‡è§£é‡Šå’Œå‚è€ƒèŒƒå›´
    """
    try:
        json_path = os.path.join(os.path.dirname(__file__), 'indicator_info.json')
        with open(json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        logger.error(f"æœªæ‰¾åˆ°æŒ‡æ ‡ä¿¡æ¯æ–‡ä»¶: {json_path}")
        return {}
    except Exception as e:
        logger.error(f"åŠ è½½æŒ‡æ ‡ä¿¡æ¯å¤±è´¥: {e}")
        return {}

@app.route('/api/indicator-info', methods=['GET'])
def get_indicator_info():
    """
    è·å–æŠ€æœ¯æŒ‡æ ‡è§£é‡Šå’Œå‚è€ƒèŒƒå›´
    æŸ¥è¯¢å‚æ•°:
    - indicator: æŒ‡æ ‡åç§°ï¼ˆå¯é€‰ï¼‰ï¼Œä¸æä¾›åˆ™è¿”å›æ‰€æœ‰æŒ‡æ ‡ä¿¡æ¯
    """
    indicator_name = request.args.get('indicator', '').lower()
    
    # ä»JSONæ–‡ä»¶åŠ è½½æŠ€æœ¯æŒ‡æ ‡çš„è§£é‡Šå’Œå‚è€ƒèŒƒå›´
    indicator_info = _load_indicator_info()
    
    if not indicator_info:
        return jsonify({
            'success': False,
            'message': 'æŒ‡æ ‡ä¿¡æ¯æ–‡ä»¶åŠ è½½å¤±è´¥'
        }), 500
    
    # å¦‚æœæŒ‡å®šäº†æŒ‡æ ‡åç§°ï¼Œåªè¿”å›è¯¥æŒ‡æ ‡ä¿¡æ¯
    if indicator_name:
        if indicator_name in indicator_info:
            return jsonify({
                'success': True,
                'indicator': indicator_name,
                'info': indicator_info[indicator_name]
            })
        else:
            return jsonify({
                'success': False,
                'message': f'æœªæ‰¾åˆ°æŒ‡æ ‡: {indicator_name}'
            }), 404
    
    # è¿”å›æ‰€æœ‰æŒ‡æ ‡ä¿¡æ¯
    return jsonify({
        'success': True,
        'indicators': indicator_info
    })


@app.route('/', methods=['GET'])
def index():
    """
    APIé¦–é¡µ
    """
    return jsonify({
        'service': 'YFinance Stock Analysis API',
        'version': '2.0.0',
        'data_source': 'Yahoo Finance',
        'description': 'åŸºäºyfinanceçš„è‚¡ç¥¨æ•°æ®åˆ†ææœåŠ¡ï¼Œæä¾›æŠ€æœ¯æŒ‡æ ‡åˆ†æã€Kçº¿æ•°æ®æŸ¥è¯¢ç­‰åŠŸèƒ½',
        'endpoints': {
            'health': 'GET /api/health - å¥åº·æ£€æŸ¥',
            'analyze': 'GET /api/analyze/<symbol>?duration=1Y&bar_size=1day - æŠ€æœ¯åˆ†æï¼ˆè‡ªåŠ¨åŒ…å«AIåˆ†æï¼‰',
            'refresh_analyze': 'POST /api/refresh-analyze/<symbol>?duration=1Y&bar_size=1day - å¼ºåˆ¶åˆ·æ–°åˆ†æ',
            'hot_stocks': 'GET /api/hot-stocks?limit=20 - çƒ­é—¨è‚¡ç¥¨åˆ—è¡¨',
            'indicator_info': 'GET /api/indicator-info?indicator=rsi - æŒ‡æ ‡è¯´æ˜'
        },
        'note': 'å†å²Kçº¿ã€è‚¡ç¥¨ä¿¡æ¯ã€åŸºæœ¬é¢æ•°æ®å·²æ•´åˆåˆ°analyzeæ¥å£ä¸­ï¼Œä¸å†æä¾›ç‹¬ç«‹API'
    })


def main():
    """
    å¯åŠ¨APIæœåŠ¡
    """
    import os
    
    # åˆå§‹åŒ–æ•°æ®åº“
    init_database()
    
    logger.info("âœ… YFinance æ•°æ®æœåŠ¡å°±ç»ª")
    
    port = 8080
    logger.info(f"ğŸš€ APIæœåŠ¡å¯åŠ¨åœ¨ http://0.0.0.0:{port}")
    
    # å¯åŠ¨FlaskæœåŠ¡
    app.run(
        host='0.0.0.0',
        port=port,
        debug=False,
        threaded=True
    )


if __name__ == '__main__':
    main()
